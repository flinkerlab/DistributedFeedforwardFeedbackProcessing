{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc, argparse, sys, os, errno\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt;\n",
    "import seaborn as sns\n",
    "#sns.set()\n",
    "#sns.set_style('whitegrid')\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import scipy\n",
    "import sklearn\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.io import loadmat\n",
    "import IPython.display as ipd\n",
    "import IPython\n",
    "import librosa.display\n",
    "import librosa\n",
    "from pystoi import stoi\n",
    "from mcd import dtw\n",
    "import mcd.metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/scratch/xc1490/projects/tmp/python_packages')\n",
    "sys.path.append('/scratch/xc1490/projects/ecog/ALAE_1023/')\n",
    "sys.path.append('/scratch/xc1490/projects/tmp/python_packages/') #pip install --target=/home/xc1490/home/projects/tmp/python_packages package_name\n",
    "from pesq import pesq\n",
    "#PESQ (Perceptual Evaluation of Speech Quality) Wrapper for Python Users\n",
    "#https://github.com/ludlows/PESQ\n",
    "#!pip install --target=/home/xc1490/home/projects/tmp/python_packages pesq\n",
    "from metrics.pystoi_plus import stoi_plus #stoi+\n",
    "#pip install --target=/home/xc1490/home/projects/tmp/python_packages https://github.com/schmiph2/pysepm/archive/master.zip\n",
    "#https://github.com/schmiph2/pysepm\n",
    "import pysepm\n",
    "def MTF(wave, n_fft = 160):\n",
    "    S = librosa.stft(wave,n_fft=n_fft)#,hop_length=hop_length) #16000 * 0.01\n",
    "    F= np.fft.fftshift(np.log(np.abs(np.fft.fft2(np.log(np.abs(S))))))\n",
    "    return F[ :F.shape[0]//2, F.shape[1]//2 - 10: F.shape[1]//2 + 10 ]\n",
    "\n",
    "def MTF_corr(orig_wave, pred_wave):\n",
    "    F_tmp_orig = MTF(orig_wave)\n",
    "    F_tmp_pred = MTF(pred_wave)\n",
    "    F_tmp_pred_1 = F_tmp_pred[-5:,F_tmp_pred.shape[1]//2 -  4: F_tmp_pred.shape[1]//2 +  4 ]\n",
    "    #F_tmp_pred_2 = F_tmp_pred[-5:]\n",
    "    F_tmp_orig_1 = F_tmp_orig[-5:,F_tmp_orig.shape[1]//2 -  4: F_tmp_orig.shape[1]//2 +  4 ]\n",
    "    #F_tmp_orig_2 = F_tmp_orig[-5:]\n",
    "    return pearsonr(F_tmp_orig.ravel(),F_tmp_pred.ravel())[0], pearsonr(F_tmp_pred_1.ravel(),F_tmp_orig_1.ravel())[0]\n",
    "\n",
    "def mel_cep_dtw_dist(target, converted):\n",
    "    \"\"\"\n",
    "    Compute the distance between two unaligned speech waveforms\n",
    "    :param target: reference speech numpy array\n",
    "    :param converted: synthesized speech numpy array\n",
    "    :return: mel cep distance in dB\n",
    "    \"\"\"\n",
    "    total_cost = 0\n",
    "    total_frames = 0\n",
    "    for (tar, conv) in zip(target, converted):\n",
    "        tar, conv = tar.astype('float64'), conv.astype('float64')\n",
    "        cost, _ = dtw.dtw(tar, conv, mt.logSpecDbDist)\n",
    "        frames = len(tar)\n",
    "        total_cost += cost\n",
    "        total_frames += frames\n",
    "\n",
    "    return total_cost / total_frames\n",
    "def play(audio,sr=16000):\n",
    "    '''\n",
    "    audio: tensor, eg: ex['audio']\n",
    "    '''\n",
    "    if len(audio.shape) >=2:\n",
    "        audio = audio.ravel()\n",
    "    display(ipd.Audio(audio,rate=sr))\n",
    "def plot_stft(audio,ax=None,n_fft=256,hop_length=128,show=False,n_mels=128,y_axis='mel'):\n",
    "    X = librosa.stft(audio,n_fft=n_fft,hop_length=hop_length)\n",
    "    if y_axis=='mel':\n",
    "        #x_stft_db = librosa.feature.melspectrogram(x, sr=16000,n_fft=n_fft,win_length=win_length,hop_length=hop_length)\n",
    "        S = librosa.feature.melspectrogram(audio, sr=16000,n_mels=n_mels,fmax=8000,n_fft=n_fft,hop_length=hop_length)\n",
    "        #print (S.shape)\n",
    "        if show:\n",
    "            librosa.display.specshow(librosa.power_to_db(S,\n",
    "                                              ref=np.max),\n",
    "                             y_axis='mel',cmap='gray_r',ax=ax, fmax=8000)\n",
    "        else:\n",
    "            spec_db = librosa.power_to_db(S,ref=np.max)\n",
    "            #level = 80\n",
    "            #spec_db[spec_db<=-level] = -100\n",
    "            #spec_db[spec_db==-level] = -100\n",
    "            return spec_db\n",
    "    else:\n",
    "        if show:\n",
    "            specshow(librosa.amplitude_to_db(abs(X)),cmap=cm.Blues,#cm.gray_r,\n",
    "                                      sr=16000,ax=ax)\n",
    "        else:\n",
    "            return librosa.amplitude_to_db(abs(X))\n",
    "    \n",
    "def MSE_pcc(A,B,ax=None):\n",
    "    mse =np.mean(((A - B)**2/B.var()))\n",
    "    pcc = pearsonr(A.ravel(),B.ravel())[0]\n",
    "    return mse,pcc\n",
    "def analyze(predict,GT_STFT_test_spkr,audio_pred,audio_gt,mode='test',ind=-1,plot=False,mcd=None):\n",
    "    samples = predict.shape[0]\n",
    "    pcc = np.zeros([samples])\n",
    "    mse = np.zeros([samples])\n",
    "    for i in range(samples):\n",
    "        mse[i], pcc[i] = MSE_pcc(predict[i],GT_STFT_test_spkr[i])\n",
    "        #mse[i], pcc[i] = MSE_pcc(predict[i] ,GT_STFT_test_spkr[i] )\n",
    "    stois = []\n",
    "    timedur = 0#0.06\n",
    "\n",
    "    for i in range(samples):\n",
    "        stois.append(stoi(np.concatenate((np.ones([int(interval*timedur)]),\\\n",
    "                audio_pred[i*interval:(i+1)*interval],np.ones([int(interval*timedur)]))), \\\n",
    "                          np.concatenate((np.ones([int(interval*timedur)]),\\\n",
    "                audio_gt[i*interval:(i+1)*interval],np.ones([int(interval*timedur)]))), 16000, extended=False))\n",
    "    stois = np.array(stois)\n",
    "    if plot:\n",
    "        if mcd is not None:\n",
    "            fig,ax=plt.subplots(1,4,figsize=(18,4))\n",
    "            ax[3].hist(mcd,bins=50,color='m')\n",
    "            ax[3].set_title(mode+' MCD: %g(%g)' %(np.round(mcd.mean(),3),np.round(mcd.std(),3)))\n",
    "        else:\n",
    "            fig,ax=plt.subplots(1,3,figsize=(20,4))\n",
    "        #fig,ax=plt.subplots(1,3,figsize=(18,4))\n",
    "        ax[0].hist(mse,bins=25,color='b')\n",
    "        ax[0].set_title('ind '+str(ind)+' '+mode+' MSE: %g(%g)' %(np.round(mse.mean(),3),np.round(mse.std(),3)))\n",
    "        ax[1].hist(pcc,bins=50,color='g')\n",
    "        ax[1].set_title(mode+' PCC: %g(%g)' %(np.round(pcc.mean(),3),np.round(pcc.std(),3)))\n",
    "        ax[2].hist(stois,bins=50,color='r')\n",
    "        ax[2].set_title(mode+' STOI: %g(%g)' %(np.round(stois.mean(),3),np.round(stois.std(),3)))\n",
    "    return mse,pcc,stois\n",
    "def play(audio,sr=16000):\n",
    "    '''\n",
    "    audio: tensor, eg: ex['audio']\n",
    "    '''\n",
    "    if len(audio.shape) >=2:\n",
    "        audio = audio.ravel()\n",
    "    display(ipd.Audio(audio,rate=sr))\n",
    "    \n",
    "def amplitude(x,noise_db=-50,max_db=22.5,trim_noise=True):\n",
    "   if trim_noise:\n",
    "      x_db = (x+1)/2*(max_db-noise_db)+noise_db\n",
    "      if type(x) is np.ndarray:\n",
    "         return 10**(x_db/10)*(x_db>noise_db).astype(np.float32)\n",
    "      else:\n",
    "         return 10**(x_db/10)*(x_db>noise_db).float()\n",
    "   else:\n",
    "      return 10**(((x+1)/2*(max_db-noise_db)+noise_db)/10)\n",
    "    \n",
    "def log_spec_dB_dist(x, y):\n",
    "    log_spec_dB_const = 10.0 / math.log(10.0) * math.sqrt(2.0)\n",
    "    diff = x - y\n",
    "    \n",
    "    return log_spec_dB_const * math.sqrt(np.inner(diff, diff))\n",
    "    \n",
    "interval = 16383\n",
    "\n",
    "def gradient_func(val):\n",
    "    row, col = val.split('|')\n",
    "    row, col = int(row), int(col)\n",
    "    split1, split2 = df.iloc[row, col].split('/') #metric\n",
    "    format_use = float(split2)*100\n",
    "    color = 'black'#{'pass': 'green', 'fail': 'red', 'warn': 'orange'}.get(status, 'gray')\n",
    "    if col!=4: \n",
    "        return '<a href=\"{sample_id}/result_final_{sample_id}.html\" style=\"color: {color}\"><span style=\"background: linear-gradient(90deg, rgba(61,164,166,1) {format_use}%, transparent 0%)\">{split1:.3f}|{split2:.3f}</span></a>'.format(\n",
    "            sample_id= df.columns[col][2:] ,  color=color, split1=float(split1),split2=float(split2),format_use=format_use)\n",
    "    else:\n",
    "        return '<span style=\"background: linear-gradient(90deg, rgba(61,164,166,1) {format_use}%, transparent 0%)\">{split1:.3f}|{split2:.3f}</span>'.format(\n",
    "            sample_id=df.columns[col], area_id =df.index[row], color=color, split1=float(split1),split2=float(split2),format_use=format_use)\n",
    "\n",
    "#df_index.style.format(style_func)\n",
    "def display_dataframe(df, filename=None, encoding='utf-8', format='csv', type='button',gradientfunc=False, **kwargs):\n",
    "    #display(df)\n",
    "    #if isinstance(df, pd.DataFrame):\n",
    "    #    display(df.style.set_caption(filename))\n",
    "    #else:\n",
    "    if gradientfunc == False:\n",
    "        display(df.style.set_caption(filename))    \n",
    "    else:\n",
    "        display(df.style.format(gradient_func).set_caption(filename)) \n",
    "    if filename is None:\n",
    "        filename = \"dataframe\"\n",
    "    if format == 'csv':\n",
    "        data = df.to_csv(**kwargs)\n",
    "        mime_type = 'text/csv'\n",
    "        filename = filename + '.csv'\n",
    "    elif format == 'tsv':\n",
    "        data = df.to_csv(**kwargs)\n",
    "        mime_type = 'text/plain'\n",
    "        filename = filename + '.txt'\n",
    "    else:\n",
    "        raise ValueError('unknown file format: {}'.format(format))\n",
    "    data = 'data:{mime_type};base64,'.format(mime_type=mime_type) + str(b64encode(bytes(data, encoding=encoding)), encoding=encoding)\n",
    "    if type == 'hyperlink':\n",
    "        display(HTML('<a href=\" \" download={filename} target=\"_blank\">{filename}</a >'.format(\n",
    "            mime_type=mime_type, filename=filename, data=data)))\n",
    "    elif type == 'button':\n",
    "        button_id = 'button_{}'.format(np.random.randint(1000000000))\n",
    "        display(HTML(r'<input type=\"button\" id=\"{0}\" value=\"Download\">'.format(button_id)))\n",
    "        display(HTML('''<script>\n",
    "    document.getElementById(\"{button_id}\").addEventListener(\"click\", function(event){{\n",
    "        var filename = \"{filename}\";\n",
    "        var data = \"{data}\";\n",
    "        const element = document.createElement('a');\n",
    "        element.setAttribute('href', data);\n",
    "        element.setAttribute('download', filename);\n",
    "        element.style.display = 'none';\n",
    "        document.body.appendChild(element);\n",
    "        element.click();\n",
    "        document.body.removeChild(element);\n",
    "    }});\n",
    "</script>'''.format(button_id=button_id, filename=filename, data=data)))\n",
    "        \n",
    "from matplotlib.backends.backend_pdf import PdfPages, PdfFile\n",
    "from IPython.display import HTML, display, FileLink\n",
    "from base64 import b64encode, b64decode\n",
    "from io import StringIO, BytesIO\n",
    "from contextlib import contextmanager\n",
    "\n",
    "#.wav: wave_rec; wave_rec_ecog:ecog.wav; \n",
    "DEBUG = False\n",
    "def get_result_dict(model_dir, sampleind):\n",
    "    #print ([int(i.split('.')[1].split('_')[-1]) for i in os.listdir(model_dir) if i.endswith('npy')])\n",
    "    epooch = int(np.max([int(i.split('_')[1] ) for i in os.listdir(model_dir) if i.endswith('.png.wav')]))\n",
    "    print ('max epoch', epooch)\n",
    "    result_dict = {}#np.load(model_dir+'sample_{}_NY{}.png_sample_npy_{}.npy'.format(epooch,sampleind,epooch),allow_pickle=1).item()\n",
    "    #print (result_dict.keys())\n",
    "    wave_key_list = ['wave_org','wave_rec_ecog','wave_rec' ]\n",
    "    print (model_dir.split('_ldw_')[0].split('_')[-1]) \n",
    "    wave_gt = np.load('/scratch/xc1490/projects/ecog/ALAE_1023/data/data/LD_gt_wave/NY{}.npy'.format(sampleind ))\n",
    "    result_dict['wave_org'] = wave_gt\n",
    "    result_dict['wave_rec_ecog'] =librosa.core.load(model_dir+'sample_{}_NY{}.pngecog.wav'.format(epooch,sampleind),sr=16000)[0]\n",
    "    result_dict['wave_rec'] =librosa.core.load(model_dir+'sample_{}_NY{}.png.wav'.format(epooch,sampleind),sr=16000)[0]\n",
    "    \n",
    "    if DEBUG:\n",
    "        display(ipd.Audio(wave_gt ,rate=16000))\n",
    "        display(ipd.Audio(result_dict['wave_rec_ecog'] ,rate=16000))\n",
    "        display(ipd.Audio(result_dict['wave_rec'] ,rate=16000))\n",
    "    return result_dict\n",
    "\n",
    "def get_result_dict(model_dir, sampleind):\n",
    "    #print ([int(i.split('.')[1].split('_')[-1]) for i in os.listdir(model_dir) if i.endswith('npy')])\n",
    "    #import pdb; pdb.set_trace()\n",
    "    epooch = int(np.max([int(i.split('.')[1].split('_')[-1]) for i in os.listdir(model_dir) if i.endswith('npy')]))\n",
    "    print ('max epoch', epooch)\n",
    "    result_dict = np.load(model_dir+'sample_{}_NY{}.png_sample_npy_{}.npy'.format(epooch,sampleind,epooch),allow_pickle=1).item()\n",
    "    #print (result_dict.keys())\n",
    "    wave_key_list = [ 'wave_rec','wave_rec_denoise','wave_rec_ecog','wave_rec_ecog_denoise']\n",
    "    for key in result_dict.keys():\n",
    "        if key!='components' and key!='components_ecog' and key!='lable':\n",
    "            #print (key)\n",
    "            #print (key,result_dict[key].shape)\n",
    "            #if key =='org_denoise':\n",
    "            #    result_dict[key] = amplitude(result_dict[key])\n",
    "            if key =='rec_denoise' or key =='rec_ecog' or key =='rec_ecog_denoise' or key =='org' or key =='rec':\n",
    "                result_dict[key] = (result_dict[key]-0.5)*2\n",
    "            if key in wave_key_list:\n",
    "                #print (key)\n",
    "                #import pdb;pdb.set_trace()\n",
    "                factor = np.sqrt(sum(result_dict['wave_org']**2)/sum(result_dict[key]**2))\n",
    "                result_dict[key] = result_dict[key]*factor\n",
    "    for key in ['org','rec','rec_ecog','rec_ecog_denoise','rec_ecog','rec_denoise']:\n",
    "        result_dict[key] = np.swapaxes(result_dict[key].reshape(256,50,-1),1,0)\n",
    "    return result_dict\n",
    "\n",
    "sample_num = 50\n",
    "def get_metric_from_result_dict(result_dict,fs = 16000):\n",
    "    wave_gt = result_dict['wave_org'].ravel()#[10*interval:]\n",
    "    wave_pred =result_dict['wave_rec_ecog'][:819582//interval*interval].ravel()#[10*interval:]\n",
    "\n",
    "    spec_pred_mel = np.zeros([sample_num,32,127])\n",
    "    spec_gt_mel = np.zeros([sample_num,32,127])\n",
    "\n",
    "    for i in  range(sample_num):\n",
    "        spec_pred_mel[i] = plot_stft(wave_pred[i*interval:(i+1)*interval],n_fft=511,hop_length=129,ax=None ,y_axis='mel',n_mels=32)\n",
    "        spec_gt_mel[i] = plot_stft(wave_gt[i*interval:(i+1)*interval],n_fft=511,hop_length=129,ax=None,y_axis='mel',n_mels=32 )\n",
    "    spec_concat_e2a = np.concatenate(( np.flip(spec_gt_mel,axis=1), np.flip(spec_pred_mel,axis=1)),axis=1)\n",
    "    \n",
    "    mse_test_e2a,pcc_test_e2a,stois_test_e2a = analyze(spec_pred_mel,spec_gt_mel,wave_pred,wave_gt,plot=False,mcd=None)\n",
    "\n",
    "\n",
    "    wave_pred =result_dict['wave_rec'][:819582//interval*interval].ravel()#[10*interval:]\n",
    "    MTF_cc_a2a = np.zeros([sample_num])\n",
    "    MTF_cc_a2a1 = np.zeros([sample_num])\n",
    "    for i in  range(sample_num):\n",
    "        MTF_cc_a2a[i],MTF_cc_a2a1[i] = MTF_corr(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval])\n",
    "    \n",
    "    stoi_extended_a2a = np.array([stoi(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], fs, extended=True) for i in   range(sample_num) ])\n",
    "    stoi_plus_a2a = np.array([stoi_plus(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], fs, extended=False) for i in   range(sample_num) ])\n",
    "    pesq_wb_a2a = np.zeros([sample_num])\n",
    "    pesq_wb_a2a[:] = numpy.nan\n",
    "    for i in range(sample_num) :\n",
    "        try:\n",
    "            pesq_wb_a2a[i] =  pesq(fs, wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], 'wb') \n",
    "        except:\n",
    "            pass\n",
    "    pesq_nb_a2a = np.zeros([sample_num])\n",
    "    pesq_nb_a2a[:] = numpy.nan\n",
    "    for i in range(sample_num) :\n",
    "        try:\n",
    "            pesq_nb_a2a[i] =  pesq(fs, wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], 'nb') \n",
    "        except:\n",
    "            pass\n",
    "    csii_a2a = np.array([pysepm.csii(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], fs ) for i in  range(sample_num) ])\n",
    "    ncm_a2a = np.zeros([sample_num]) #np.array([pysepm.ncm(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], fs ) for i in  range(sample_num) ])\n",
    "    \n",
    "    \n",
    "    #stoi(gt_audio, pred_audio, fs, extended=False)\n",
    "    #stoi(gt_audio, pred_audio, fs, extended=True)\n",
    "    #stoi_plus(gt_audio, pred_audio, fs, extended=False)\n",
    "    #pesq(fs, gt_audio, pred_audio, 'wb')  #pesq_batch for batch processing\n",
    "    #pesq(fs, gt_audio, pred_audio, 'nb')\n",
    "    #pysepm.csii(gt_audio, pred_audio, fs) #high, mid, low\n",
    "    #pysepm.ncm(gt_audio, pred_audio, fs)\n",
    "    \n",
    "    spec_pred_mel = np.zeros([sample_num,32,127])\n",
    "    spec_gt_mel = np.zeros([sample_num,32,127])\n",
    "\n",
    "    for i in  range(sample_num):\n",
    "        spec_pred_mel[i] = plot_stft(wave_pred[i*interval:(i+1)*interval],n_fft=511,hop_length=129,ax=None ,y_axis='mel',n_mels=32)\n",
    "        spec_gt_mel[i] = plot_stft(wave_gt[i*interval:(i+1)*interval],n_fft=511,hop_length=129,ax=None,y_axis='mel',n_mels=32 )\n",
    "    spec_concat_a2a = np.concatenate(( np.flip(spec_gt_mel,axis=1), np.flip(spec_pred_mel,axis=1)),axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    mse_test_a2a,pcc_test_a2a,stois_test_a2a = analyze(spec_pred_mel,spec_gt_mel,wave_pred,wave_gt,plot=False,mcd=None)\n",
    "\n",
    "    #mfcc e2a\n",
    "    wave_pred =result_dict['wave_rec_ecog'][:819582//interval*interval].ravel()#[10*interval:]\n",
    "    \n",
    "    MTF_cc_e2a = np.zeros([sample_num])\n",
    "    MTF_cc_e2a1 = np.zeros([sample_num])\n",
    "    for i in  range(sample_num):\n",
    "        MTF_cc_e2a[i],MTF_cc_e2a1[i] = MTF_corr(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval])\n",
    "    stoi_extended_e2a = np.array([stoi(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], fs, extended=True) for i in  range(sample_num)])\n",
    "    stoi_plus_e2a = np.array([stoi_plus(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], fs, extended=False) for i in  range(sample_num)])\n",
    "    pesq_wb_e2a = np.zeros([sample_num])\n",
    "    pesq_wb_e2a[:] = numpy.nan\n",
    "    for i in  range(sample_num):\n",
    "        try:\n",
    "            pesq_wb_e2a[i] =  pesq(fs, wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], 'wb') \n",
    "        except:\n",
    "            pass\n",
    "    pesq_nb_e2a = np.zeros([sample_num])\n",
    "    pesq_nb_e2a[:] = numpy.nan\n",
    "    for i in  range(sample_num):\n",
    "        try:\n",
    "            pesq_nb_e2a[i] =  pesq(fs, wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], 'nb') \n",
    "        except:\n",
    "            pass\n",
    "    csii_e2a = np.array([pysepm.csii(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], fs ) for i in  range(sample_num)])\n",
    "    ncm_e2a =  np.zeros([sample_num])#np.array([pysepm.ncm(wave_gt[i*interval:(i+1)*interval], wave_pred[i*interval:(i+1)*interval], fs ) for i in  range(sample_num)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    spec_pred = np.zeros([sample_num,32,32])\n",
    "    spec_gt = np.zeros([sample_num,32,32])\n",
    "    mfcc_e2a = np.zeros([sample_num])\n",
    "    for i in  range(sample_num):\n",
    "        spec_pred[i] = librosa.feature.mfcc(y=wave_pred[i*interval:(i+1)*interval], sr=16000,n_mfcc=32)\n",
    "        spec_gt[i] = librosa.feature.mfcc(y=wave_gt[i*interval:(i+1)*interval], sr=16000,n_mfcc=32)\n",
    "        mfcc_e2a[i] = pearsonr(spec_pred[i].ravel(),spec_gt[i].ravel())[0]\n",
    "\n",
    "    #mfcc a2a\n",
    "    wave_pred =result_dict['wave_rec'][:819582//interval*interval].ravel()#[10*interval:]\n",
    "    spec_pred = np.zeros([sample_num,32,32])\n",
    "    spec_gt = np.zeros([sample_num,32,32])\n",
    "\n",
    "    mfcc_a2a = np.zeros([sample_num])\n",
    "    for i in  range(sample_num):\n",
    "        spec_pred[i] = librosa.feature.mfcc(y=wave_pred[i*interval:(i+1)*interval], sr=16000,n_mfcc=32)\n",
    "        spec_gt[i] = librosa.feature.mfcc(y=wave_gt[i*interval:(i+1)*interval], sr=16000,n_mfcc=32)\n",
    "        mfcc_a2a[i] = pearsonr(spec_pred[i].ravel(),spec_gt[i].ravel())[0]\n",
    "\n",
    "    components_keys = ['f0','loudness', 'amplitudes', 'amplitudes_h', 'freq_formants_hamon_hz', 'bandwidth_formants_hamon_hz', 'amplitude_formants_hamon','freq_formants_noise_hz', 'bandwidth_formants_noise_hz', 'amplitude_formants_noise']\n",
    "    components_pcc = {}\n",
    "    #for key in components_keys:\n",
    "    #    components_pcc[key] = np.zeros([50])\n",
    "    #    for i in range(50):\n",
    "    #        components_pcc[key][i] =pearsonr((result_dict['components'][key][i] *(result_dict['components']['amplitudes'][i,0:1,:]  >=0.2)).ravel(),\\\n",
    "    #                        (result_dict['components_ecog'][key][i] *(result_dict['components']['amplitudes'][i,0:1,:]  >=0.2)).ravel())[0]\n",
    "    #    #print (key,result_dict['components'][key].shape,np.mean(components_pcc[key]))\n",
    "    return mse_test_e2a, pcc_test_e2a, stois_test_e2a, None, mfcc_e2a, \\\n",
    "            mse_test_a2a, pcc_test_a2a, stois_test_a2a, None, mfcc_a2a, components_pcc, MTF_cc_a2a, MTF_cc_e2a, \\\n",
    "            MTF_cc_a2a1, MTF_cc_e2a1, stoi_extended_a2a, stoi_plus_a2a, pesq_wb_a2a, pesq_nb_a2a, csii_a2a, ncm_a2a,\\\n",
    "            stoi_extended_e2a, stoi_plus_e2a, pesq_wb_e2a, pesq_nb_e2a, csii_e2a, ncm_e2a\n",
    "\n",
    "import json\n",
    "with open('/scratch/xc1490/home/projects/ecog/ALAE_1023/AllSubjectInfo.json','r') as rfile:\n",
    "    allsubj_param = json.load(rfile)\n",
    "\n",
    "def display_and_plot(pcc_onset, result_dict,sample_ind):\n",
    "    subj_param = allsubj_param['Subj']['NY'+str(sample_ind)]\n",
    "    Gender = subj_param['Gender']\n",
    "    print ('*'*20,sample_ind, Gender,'*'*20)\n",
    "    wave_gt = result_dict['wave_org'].ravel()\n",
    "    wave_pred_a2a = result_dict['wave_rec'].ravel()\n",
    "    wave_pred = result_dict['wave_rec_ecog'].ravel()\n",
    "    wave_merge = np.concatenate(([np.concatenate((wave_gt[i*interval:(i+1)*interval],wave_pred[i*interval:(i+1)*interval]))\\\n",
    "                     for i in range(50)]))\n",
    "\n",
    "    print ('original')\n",
    "    display(ipd.Audio(wave_gt.reshape(50,-1)[np.argsort(-pcc_onset)].ravel(),rate=16000))\n",
    "    print ('a2a pred')\n",
    "    display(ipd.Audio(wave_pred_a2a.reshape(50,-1)[np.argsort(-pcc_onset)].ravel(),rate=16000))\n",
    "    print ('e2a pred')\n",
    "    display(ipd.Audio(wave_pred.reshape(50,-1)[np.argsort(-pcc_onset)].ravel(),rate=16000))\n",
    "    print ('merge of orig and e2a pred')\n",
    "    display(ipd.Audio(wave_merge.reshape(50,-1)[np.argsort(-pcc_onset)].ravel(),rate=16000))\n",
    "    if Gender == 'Female':\n",
    "        N_FFT = 511 \n",
    "        plot_factor = 1\n",
    "    else:\n",
    "        N_FFT =1023\n",
    "        plot_factor = 1.6\n",
    "    spec_dim = 127\n",
    "    spec_pred = np.zeros([50,(N_FFT+1)//2,spec_dim])\n",
    "    spec_gt = np.zeros([50,(N_FFT+1)//2,spec_dim])\n",
    "    try:\n",
    "        select_word = np.loadtxt('/scratch/xc1490/home/projects/ecog/ALAE_1023/data/wordlist_NY{}.txt'.format(sample_ind),dtype='str')\n",
    "    except:\n",
    "        select_word = np.array(['' for i in range(50)])\n",
    "    #print (select_word)\n",
    "    \n",
    "    \n",
    "    #MTF(wave, n_fft = 160)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #np.concatenate([wave_pred[i*interval:(i+1)*interval] for i in range(50)])\n",
    "    for i in range(50):\n",
    "        spec_pred[i] = plot_stft(wave_pred[i*interval:(i+1)*interval],n_fft=N_FFT,hop_length=129,ax=None ,y_axis='linear',n_mels=32)\n",
    "        spec_gt[i] = plot_stft(wave_gt[i*interval:(i+1)*interval],n_fft=N_FFT,hop_length=129,ax=None,y_axis='linear',n_mels=32 )\n",
    "        #spec_pred[i] = plot_stft(wave_pred[i*interval:(i+1)*interval],n_fft=511,hop_length=129,ax=None ,y_axis='linear',n_mels=256)\n",
    "        #spec_gt[i] = plot_stft(wave_gt[i*interval:(i+1)*interval],n_fft=511,hop_length=129,ax=None,y_axis='linear',n_mels=256 )\n",
    "    spec_concat = np.concatenate(( np.flip(spec_gt,axis=1), np.flip(spec_pred,axis=1)),axis=1)\n",
    "\n",
    "    \n",
    "    row_nums = 5\n",
    "    col_nums = 10\n",
    "    fig,ax=plt.subplots(row_nums,col_nums,figsize=(col_nums*1.4,row_nums*4*plot_factor))\n",
    "    cmap = cm.gray_r\n",
    "    for i in range(row_nums):\n",
    "        for j in range(col_nums):\n",
    "            ax[i,j].imshow(spec_concat[np.argsort(-pcc_onset)[i*col_nums+j]] ,cmap=cmap)\n",
    "            #try:\n",
    "            ax[i,j].set_title(select_word[np.argsort(-pcc_onset)[i*col_nums+j]]+' {0:.3g}'.format(pcc_onset[np.argsort(-pcc_onset)[i*col_nums+j]]))\n",
    "                #ax[i,j].set_title(select_word[np.argsort(-pcc_test)[i*col_nums+j]]+' {0:.3g}'.format(-np.sort(-pcc_test)[i*col_nums+j]))\n",
    "            #except:\n",
    "            #    pass\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/scratch/xc1490/projects/ecog/ALAE_1023/AllSubjectInfo.json','r') as rfile:\n",
    "    allsubj_param = json.load(rfile)\n",
    "total_samples = np.sort([sample for sample in allsubj_param['Subj'].keys() if \\\n",
    "                          allsubj_param['Subj'][sample]['Density'] == 'LD' and 'female' not in sample])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = ['../output/resnet_NY869/']\n",
    "sample_inds_use = np.repeat('869',len(model_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39f990518e04d85828df229999ebbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max epoch 51\n",
      "************************* 869 *************************\n",
      "../output/resnet_NY869/\n"
     ]
    }
   ],
   "source": [
    "mse_test_e2a_dict, pcc_test_e2a_dict, stois_test_e2a_dict, mcd_e2a_dict, mfcc_e2a_dict, \\\n",
    "  mse_test_a2a_dict, pcc_test_a2a_dict, stois_test_a2a_dict, mcd_a2a_dict, mfcc_a2a_dict, \\\n",
    "    components_pcc_dict, MTF_cc_a2a_dict, MTF_cc_e2a_dict, MTF_cc_a2a_dict1, MTF_cc_e2a_dict1,\\\n",
    "    stoi_extended_a2a_dict, stoi_plus_a2a_dict, pesq_wb_a2a_dict, pesq_nb_a2a_dict, csii_a2a_dict, ncm_a2a_dict,\\\n",
    "    stoi_extended_e2a_dict, stoi_plus_e2a_dict, pesq_wb_e2a_dict, pesq_nb_e2a_dict, csii_e2a_dict, ncm_e2a_dict = \\\n",
    "            {},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{},{}\n",
    "count = 0\n",
    "sample_ind_correct1 = np.arange(len(sample_inds_use))\n",
    "for ind, sample_ind_ in tqdm(enumerate(sample_inds_use  )):\n",
    "    try:\n",
    "        result_dict = get_result_dict(model_dir[ind],sample_ind_)\n",
    "        sample_ind = sample_ind_\n",
    "        print ('*'*25,sample_ind,'*'*25)\n",
    "        print (model_dir[ind])\n",
    "        mse_test_e2a_dict[sample_ind], pcc_test_e2a_dict[sample_ind], stois_test_e2a_dict[sample_ind], \\\n",
    "        mcd_e2a_dict[sample_ind], mfcc_e2a_dict[sample_ind], mse_test_a2a_dict[sample_ind], pcc_test_a2a_dict[sample_ind],\\\n",
    "        stois_test_a2a_dict[sample_ind], mcd_a2a_dict[sample_ind], mfcc_a2a_dict[sample_ind], components_pcc_dict[sample_ind], \\\n",
    "        MTF_cc_a2a_dict[sample_ind], MTF_cc_e2a_dict[sample_ind],MTF_cc_a2a_dict1[sample_ind], MTF_cc_e2a_dict1[sample_ind],\\\n",
    "        stoi_extended_a2a_dict[sample_ind], stoi_plus_a2a_dict[sample_ind], pesq_wb_a2a_dict[sample_ind], pesq_nb_a2a_dict[sample_ind],\\\n",
    "        csii_a2a_dict[sample_ind], ncm_a2a_dict[sample_ind],stoi_extended_e2a_dict[sample_ind], stoi_plus_e2a_dict[sample_ind], pesq_wb_e2a_dict[sample_ind],\\\n",
    "        pesq_nb_e2a_dict[sample_ind], csii_e2a_dict[sample_ind], ncm_e2a_dict[sample_ind] \\\n",
    "        = get_metric_from_result_dict(result_dict)\n",
    "\n",
    "        pcc_onset = pcc_test_e2a_dict[sample_ind]\n",
    "        display_and_plot(pcc_onset, result_dict,sample_ind_)\n",
    "        count += 1\n",
    "    except:\n",
    "        print (sample_ind_, 'error')\n",
    "        sample_ind_correct1 = np.setdiff1d(sample_ind_correct1, np.array([ind]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'ResNet'\n",
    "\n",
    "mse_new = np.zeros([4,count ])#actually a2a 4 metric* 3 sample\n",
    "\n",
    "for j in range(len(sample_ind_correct1)):\n",
    "    mse_new[0,j] = np.mean(pcc_test_a2a_dict[sample_inds_use[sample_ind_correct1[j]]])\n",
    "    mse_new[1,j] = np.mean(stois_test_a2a_dict[sample_inds_use[sample_ind_correct1[j]]])\n",
    "    mse_new[2,j] = np.mean(mfcc_a2a_dict[sample_inds_use[sample_ind_correct1[j]]])\n",
    "    mse_new[3,j] = np.mean(MTF_cc_a2a_dict[sample_inds_use[sample_ind_correct1[j]]])\n",
    "    #mse_new[3,j] = np.mean(mcd_a2a_dict[sample_inds[j]])\n",
    "\n",
    "pcc_new = np.zeros([4,count ])#actually e2a 4 metric* 3 sample\n",
    "\n",
    "\n",
    "for j in range(count ):\n",
    "    pcc_new[0,j] = np.mean(pcc_test_e2a_dict[sample_inds_use[sample_ind_correct1[j]]])\n",
    "    pcc_new[1,j] = np.mean(stois_test_e2a_dict[sample_inds_use[sample_ind_correct1[j]]])\n",
    "    pcc_new[2,j] = np.mean(mfcc_e2a_dict[sample_inds_use[sample_ind_correct1[j]]])\n",
    "    pcc_new[3,j] = np.mean(MTF_cc_e2a_dict[sample_inds_use[sample_ind_correct1[j]]])\n",
    "    #pcc_new[3,j] = np.mean(mcd_e2a_dict[sample_inds[j]])\n",
    "\n",
    "df_new = pd.DataFrame(np.zeros([4,count ]))\n",
    "df_new = df_new.astype('str')\n",
    "for i in range(4):\n",
    "    for j in range(count ):\n",
    "        df_new.iloc[i,j] = str(mse_new[i,j])+'/' +str(pcc_new[i,j])\n",
    "#for i in range(3):\n",
    "#    df_new.iloc[i,count ] = str(np.round(np.mean(mse_new[i,:]),3))+'/' +str(np.round(np.mean(pcc_new[i,:]),3))\n",
    "df_new.columns = ['NY{}'.format(sample_inds_use[sample_ind]) for sample_ind in sample_ind_correct1] #+ ['Average']\n",
    "df_new.index = ['SPEC PCC','STOI','MFCC PCC','MTF PCC' ]\n",
    "\n",
    "df = df_new\n",
    "df_index =  pd.DataFrame(np.array([(str(i)+'|'+str(j)) for i in range(df.shape[0]) \\\n",
    "                                   for j in range(df.shape[1])]).reshape(df.shape[0],-1))\n",
    "df_index.index = df.index\n",
    "df_index.columns = df.columns\n",
    "\n",
    "#df.to_csv('formant_metric_summary_{}.csv'.format(model_dir.split('/')[1]))\n",
    "#except:\n",
    "#    print (  'error')\n",
    "\n",
    "display_dataframe(df_index.T,gradientfunc=True,filename='overall performance')\n",
    "genderlist = [allsubj_param['Subj']['NY'+str(sample_ind.split('_')[0])]['Gender'] for sample_ind in np.array(sample_inds_use)[sample_ind_correct1]]\n",
    "print ('\\n')\n",
    "print ('-'*100,'\\n')\n",
    "print ('{} Patients, {} Female Patients, {} Male Patients'.format(len(sample_inds_use), genderlist.count('Female'), genderlist.count('Male')))\n",
    "print ('\\n')\n",
    "print ('-'*100,'\\n')\n",
    "print ('Patient List: ',['NY'+str(sample_ind)  for sample_ind in sample_inds_use])  #patient list\n",
    "print ('\\n')\n",
    "print ('-'*100,'\\n')\n",
    "print ('Patient Gender: ',{'NY'+str(sample_ind):allsubj_param['Subj']['NY'+str(sample_ind.split('_')[0])]['Gender']  for sample_ind in sample_inds_use})  #patient gender\n",
    "\n",
    "\n",
    "task = ['Reference','Decoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
