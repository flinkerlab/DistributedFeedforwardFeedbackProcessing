{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding\n"
     ]
    }
   ],
   "source": [
    "cd /scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD = 1\n",
    "\n",
    "import torch\n",
    "from torch import optim as optim\n",
    "import torch.utils.data\n",
    "from tqdm import tqdm as tqdm\n",
    "import numpy as np\n",
    "import argparse, os, json, yaml\n",
    "from networks import *\n",
    "from model import Model\n",
    "from dataset import *\n",
    "from tracker import LossTracker\n",
    "from utils.custom_adam import LREQAdam\n",
    "from utils.checkpointer import Checkpointer\n",
    "from utils.launcher import run\n",
    "from utils.defaults import get_cfg_defaults\n",
    "from utils.save import save_sample\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cd /scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding\n",
    "python train_e2a.py --OUTPUT_DIR output/resnet_NY869 --trainsubject NY869 --testsubject NY869 --param_file configs/e2a_production.yaml --batch_size 16 --MAPPING_FROM_ECOG ECoGMapping_ResNet --reshape 1 --DENSITY \"LD\" --wavebased 1 --dynamicfiltershape 0 --n_filter_samples 80 --n_fft 512 --formant_supervision 1  --intensity_thres -1 --epoch_num 60 --pretrained_model_dir output/a2a/NY869 --causal 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "  noise_db = -50\n",
    "    \n",
    "  opts = None\n",
    "  config_file = 'configs/e2a_production.yaml'\n",
    "  DENSITY = 'LD'\n",
    "  wavebased = 1\n",
    "  bgnoise_fromdata = 1\n",
    "  ignore_loading = 0\n",
    "  finetune = 0\n",
    "  learnedmask = 0\n",
    "  dynamicfiltershape = 0\n",
    "  formant_supervision = 0\n",
    "  pitch_supervision = 0\n",
    "  intensity_supervision = 0\n",
    "  n_filter_samples = 20\n",
    "  n_fft = 512\n",
    "  reverse_order = 1\n",
    "  lar_cap = 0\n",
    "  intensity_thres = -1\n",
    "  RNN_COMPUTE_DB_LOUDNESS = 1\n",
    "  BIDIRECTION = 1\n",
    "  MAPPING_FROM_ECOG = 'ECoGMapping_ResNet'\n",
    "  OUTPUT_DIR = 'output/resnet'\n",
    "  COMPONENTKEY = ''\n",
    "  trainsubject = 'NY869'\n",
    "  testsubject = 'NY869'\n",
    "  reshape = -1\n",
    "  ld_loss_weight = 1\n",
    "  alpha_loss_weight = 1\n",
    "  consonant_loss_weight = 0\n",
    "  batch_size = 8\n",
    "  param_file = 'configs/e2a_production.yaml'\n",
    "  pretrained_model_dir = 'output/a2a/NY869'\n",
    "  causal = 0\n",
    "  anticausal = 0\n",
    "  rdropout = 0\n",
    "  epoch_num = 100\n",
    "  use_stoi = 0\n",
    "  use_denoise = 0\n",
    "\n",
    "args_ = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/AllSubjectInfo.json\", \"r\") as rfile:\n",
    "    allsubj_param = json.load(rfile)\n",
    "with open(args_.param_file, 'r') as stream:\n",
    "    param = yaml.safe_load(stream)\n",
    "(\n",
    "    ecog_all,\n",
    "    wave_orig_all,\n",
    "    x_orig_all,\n",
    "    x_orig_amp_all,\n",
    "    labels_all,\n",
    "    gender_train_all,\n",
    "    on_stage_all,\n",
    "    on_stage_wider_all\n",
    ") = ({}, {}, {}, {}, {}, {}, {}, {})\n",
    "\n",
    "hann_win = torch.hann_window(21, periodic=False).reshape([1, 1, 21, 1])\n",
    "hann_win = hann_win / hann_win.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def get_train_data(\n",
    "    ecog_all,\n",
    "    wave_orig_all,\n",
    "    x_orig_all,\n",
    "    x_orig_amp_all,\n",
    "    labels_all,\n",
    "    gender_train_all,\n",
    "    on_stage_all,\n",
    "    on_stage_wider_all,\n",
    "    sample_dict_train=None,\n",
    "    subject=None,\n",
    "):\n",
    "    wave_orig_all[subject] = (\n",
    "        sample_dict_train[\"wave_re_batch_all\"].to(device).float()\n",
    "    )\n",
    "    gender_train_all[subject] =sample_dict_train['gender_all'].to(device).float()\n",
    "    if cfg.MODEL.WAVE_BASED:\n",
    "        x_orig_all[subject] = (\n",
    "            sample_dict_train[\"wave_spec_re_batch_all\"].to(device).float()\n",
    "        )\n",
    "        x_orig_amp_all[subject] = (\n",
    "            sample_dict_train[\"wave_spec_re_amp_batch_all\"].to(device).float()\n",
    "        )\n",
    "    on_stage_all[subject] = (\n",
    "        sample_dict_train[\"on_stage_re_batch_all\"].to(device).float()\n",
    "    )\n",
    "    on_stage_wider_all[subject] = (\n",
    "        sample_dict_train[\"on_stage_wider_re_batch_all\"].to(device).float()\n",
    "    )\n",
    "    labels_all[subject] = sample_dict_train[\"label_batch_all\"]\n",
    "    ecog_all[subject] = sample_dict_train[\"ecog_re_batch_all\"].to(device).float()\n",
    "\n",
    "    return (\n",
    "        ecog_all,\n",
    "        wave_orig_all,\n",
    "        x_orig_all,\n",
    "        x_orig_amp_all,\n",
    "        labels_all,\n",
    "        gender_train_all,\n",
    "        on_stage_all,\n",
    "        on_stage_wider_all,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_model_checkpoint(\n",
    "    logger,\n",
    "    local_rank,\n",
    "    distributed,\n",
    "    tracker=None,\n",
    "    tracker_test=None,\n",
    "    dataset_all=None,\n",
    "    subject=\"NY742\",\n",
    "    load_dir=\"\",\n",
    "    single_patient_mapping=0,param=None\n",
    "):\n",
    "    if args_.trainsubject != \"\":\n",
    "        train_subject_info = args_.trainsubject.split(\",\")\n",
    "    else:\n",
    "        train_subject_info = cfg.DATASET.SUBJECT\n",
    "    model = Model(\n",
    "        generator=cfg.MODEL.GENERATOR,\n",
    "        encoder=cfg.MODEL.ENCODER,\n",
    "        ecog_encoder_name=cfg.MODEL.MAPPING_FROM_ECOG,\n",
    "        spec_chans=cfg.DATASET.SPEC_CHANS,\n",
    "        n_formants=cfg.MODEL.N_FORMANTS,\n",
    "        n_formants_noise=cfg.MODEL.N_FORMANTS_NOISE,\n",
    "        n_formants_ecog=cfg.MODEL.N_FORMANTS_ECOG,\n",
    "        wavebased=cfg.MODEL.WAVE_BASED,\n",
    "        n_fft=cfg.MODEL.N_FFT,\n",
    "        noise_db=cfg.MODEL.NOISE_DB,\n",
    "        max_db=cfg.MODEL.MAX_DB,\n",
    "        with_ecog=cfg.MODEL.ECOG,\n",
    "        do_mel_guide=cfg.MODEL.DO_MEL_GUIDE,\n",
    "        noise_from_data=cfg.MODEL.BGNOISE_FROMDATA and cfg.DATASET.PROD,\n",
    "        specsup=cfg.FINETUNE.SPECSUP,\n",
    "        power_synth=cfg.MODEL.POWER_SYNTH,\n",
    "        apply_flooding=cfg.FINETUNE.APPLY_FLOODING,\n",
    "        normed_mask=cfg.MODEL.NORMED_MASK,\n",
    "        dummy_formant=cfg.MODEL.DUMMY_FORMANT,\n",
    "        A2A=cfg.VISUAL.A2A,\n",
    "        causal=cfg.MODEL.CAUSAL,\n",
    "        anticausal=cfg.MODEL.ANTICAUSAL,\n",
    "        pre_articulate=cfg.DATASET.PRE_ARTICULATE,\n",
    "        alpha_sup=param[\"Subj\"][subject][\n",
    "            \"AlphaSup\"\n",
    "        ],\n",
    "        ld_loss_weight=cfg.MODEL.ld_loss_weight,\n",
    "        alpha_loss_weight=cfg.MODEL.alpha_loss_weight,\n",
    "        consonant_loss_weight=cfg.MODEL.consonant_loss_weight,\n",
    "        component_regression=cfg.MODEL.component_regression,\n",
    "        amp_formant_loss_weight=cfg.MODEL.amp_formant_loss_weight,\n",
    "        freq_single_formant_loss_weight=cfg.MODEL.freq_single_formant_loss_weight,\n",
    "        amp_minmax=cfg.MODEL.amp_minmax,\n",
    "        amp_energy=cfg.MODEL.amp_energy,\n",
    "        f0_midi=cfg.MODEL.f0_midi,\n",
    "        alpha_db=cfg.MODEL.alpha_db,\n",
    "        network_db=cfg.MODEL.network_db,\n",
    "        consistency_loss=cfg.MODEL.consistency_loss,\n",
    "        delta_time=cfg.MODEL.delta_time,\n",
    "        delta_freq=cfg.MODEL.delta_freq,\n",
    "        cumsum=cfg.MODEL.cumsum,\n",
    "        distill=cfg.MODEL.distill,\n",
    "        learned_mask=cfg.MODEL.LEARNED_MASK,\n",
    "        n_filter_samples=cfg.MODEL.N_FILTER_SAMPLES,\n",
    "        patient=subject,\n",
    "        batch_size=cfg.TRAIN.BATCH_SIZE,\n",
    "        rdropout=cfg.MODEL.rdropout,\n",
    "        dynamic_filter_shape=cfg.MODEL.DYNAMIC_FILTER_SHAPE,\n",
    "        learnedbandwidth=cfg.MODEL.LEARNEDBANDWIDTH,\n",
    "        gender_patient=allsubj_param[\"Subj\"][train_subject_info[0]][\"Gender\"],\n",
    "        reverse_order=args_.reverse_order,\n",
    "        larger_capacity=args_.lar_cap,\n",
    "        use_stoi=args_.use_stoi,\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda(local_rank)\n",
    "    model.train()\n",
    "\n",
    "    model_s = Model(\n",
    "        generator=cfg.MODEL.GENERATOR,\n",
    "        encoder=cfg.MODEL.ENCODER,\n",
    "        ecog_encoder_name=cfg.MODEL.MAPPING_FROM_ECOG,\n",
    "        spec_chans=cfg.DATASET.SPEC_CHANS,\n",
    "        n_formants=cfg.MODEL.N_FORMANTS,\n",
    "        n_formants_noise=cfg.MODEL.N_FORMANTS_NOISE,\n",
    "        n_formants_ecog=cfg.MODEL.N_FORMANTS_ECOG,\n",
    "        wavebased=cfg.MODEL.WAVE_BASED,\n",
    "        n_fft=cfg.MODEL.N_FFT,\n",
    "        noise_db=cfg.MODEL.NOISE_DB,\n",
    "        max_db=cfg.MODEL.MAX_DB,\n",
    "        with_ecog=cfg.MODEL.ECOG,\n",
    "        do_mel_guide=cfg.MODEL.DO_MEL_GUIDE,\n",
    "        noise_from_data=cfg.MODEL.BGNOISE_FROMDATA and cfg.DATASET.PROD,\n",
    "        specsup=cfg.FINETUNE.SPECSUP,\n",
    "        power_synth=cfg.MODEL.POWER_SYNTH,\n",
    "        apply_flooding=cfg.FINETUNE.APPLY_FLOODING,\n",
    "        normed_mask=cfg.MODEL.NORMED_MASK,\n",
    "        dummy_formant=cfg.MODEL.DUMMY_FORMANT,\n",
    "        A2A=cfg.VISUAL.A2A,\n",
    "        causal=cfg.MODEL.CAUSAL,\n",
    "        anticausal=cfg.MODEL.ANTICAUSAL,\n",
    "        pre_articulate=cfg.DATASET.PRE_ARTICULATE,\n",
    "        alpha_sup=param[\"Subj\"][subject][\n",
    "            \"AlphaSup\"\n",
    "        ],\n",
    "        ld_loss_weight=cfg.MODEL.ld_loss_weight,\n",
    "        alpha_loss_weight=cfg.MODEL.alpha_loss_weight,\n",
    "        consonant_loss_weight=cfg.MODEL.consonant_loss_weight,\n",
    "        component_regression=cfg.MODEL.component_regression,\n",
    "        amp_formant_loss_weight=cfg.MODEL.amp_formant_loss_weight,\n",
    "        freq_single_formant_loss_weight=cfg.MODEL.freq_single_formant_loss_weight,\n",
    "        amp_minmax=cfg.MODEL.amp_minmax,\n",
    "        amp_energy=cfg.MODEL.amp_energy,\n",
    "        f0_midi=cfg.MODEL.f0_midi,\n",
    "        alpha_db=cfg.MODEL.alpha_db,\n",
    "        network_db=cfg.MODEL.network_db,\n",
    "        consistency_loss=cfg.MODEL.consistency_loss,\n",
    "        delta_time=cfg.MODEL.delta_time,\n",
    "        delta_freq=cfg.MODEL.delta_freq,\n",
    "        cumsum=cfg.MODEL.cumsum,\n",
    "        distill=cfg.MODEL.distill,\n",
    "        learned_mask=cfg.MODEL.LEARNED_MASK,\n",
    "        n_filter_samples=cfg.MODEL.N_FILTER_SAMPLES,\n",
    "        patient=subject,\n",
    "        batch_size=cfg.TRAIN.BATCH_SIZE,\n",
    "        rdropout=cfg.MODEL.rdropout,\n",
    "        dynamic_filter_shape=cfg.MODEL.DYNAMIC_FILTER_SHAPE,\n",
    "        learnedbandwidth=cfg.MODEL.LEARNEDBANDWIDTH,\n",
    "        gender_patient=allsubj_param[\"Subj\"][train_subject_info[0]][\"Gender\"],\n",
    "        reverse_order=args_.reverse_order,\n",
    "        larger_capacity=args_.lar_cap,\n",
    "        use_stoi=args_.use_stoi,\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        model_s.cuda(local_rank)\n",
    "    model_s.eval()\n",
    "    model_s.requires_grad_(False)\n",
    "    if distributed:\n",
    "        model = nn.parallel.DistributedDataParallel(\n",
    "            model,\n",
    "            device_ids=[local_rank],\n",
    "            broadcast_buffers=False,\n",
    "            bucket_cap_mb=25,\n",
    "            find_unused_parameters=True,\n",
    "        )\n",
    "        model.device_ids = None\n",
    "        decoder = model.module.decoder\n",
    "        encoder = model.module.encoder\n",
    "        if hasattr(model.module, \"ecog_encoder\"):\n",
    "            ecog_encoder = model.module.ecog_encoder\n",
    "            if torch.cuda.is_available():\n",
    "                ecog_encoder = ecog_encoder.cuda(local_rank)\n",
    "            # ecog_encoder.performer.cuda(local_rank)\n",
    "        if hasattr(model.module, \"decoder_mel\"):\n",
    "            decoder_mel = model.module.decoder_mel\n",
    "    else:\n",
    "        decoder = model.decoder\n",
    "        encoder = model.encoder\n",
    "        if hasattr(model, \"ecog_encoder\"):\n",
    "            ecog_encoder = model.ecog_encoder\n",
    "            if torch.cuda.is_available():\n",
    "                ecog_encoder = ecog_encoder.cuda(local_rank)\n",
    "        if hasattr(model, \"decoder_mel\"):\n",
    "            decoder_mel = model.decoder_mel\n",
    "    logger.info(\"Trainable parameters generator:\")\n",
    "    logger.info(\"Trainable parameters discriminator:\")\n",
    "    arguments = dict()\n",
    "    arguments[\"iteration\"] = 0\n",
    "\n",
    "    if cfg.MODEL.ECOG:\n",
    "        if cfg.MODEL.SUPLOSS_ON_ECOGF:\n",
    "            optimizer = LREQAdam(\n",
    "                [{\"params\": ecog_encoder.parameters()}],\n",
    "                lr=cfg.TRAIN.BASE_LEARNING_RATE,\n",
    "                betas=(cfg.TRAIN.ADAM_BETA_0, cfg.TRAIN.ADAM_BETA_1),\n",
    "                weight_decay=0,\n",
    "            )\n",
    "        else:\n",
    "            optimizer = LREQAdam(\n",
    "                [\n",
    "                    {\"params\": ecog_encoder.parameters()},\n",
    "                    {\"params\": decoder.parameters()},\n",
    "                ],\n",
    "                lr=cfg.TRAIN.BASE_LEARNING_RATE,\n",
    "                betas=(cfg.TRAIN.ADAM_BETA_0, cfg.TRAIN.ADAM_BETA_1),\n",
    "                weight_decay=0,\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        if cfg.MODEL.DO_MEL_GUIDE:\n",
    "            optimizer = LREQAdam(\n",
    "                [\n",
    "                    {\"params\": encoder.parameters()},\n",
    "                    {\"params\": decoder.parameters()},\n",
    "                    {\"params\": decoder_mel.parameters()},\n",
    "                ],\n",
    "                lr=cfg.TRAIN.BASE_LEARNING_RATE,\n",
    "                betas=(cfg.TRAIN.ADAM_BETA_0, cfg.TRAIN.ADAM_BETA_1),\n",
    "                weight_decay=0,\n",
    "            )\n",
    "        else:\n",
    "            optimizer = LREQAdam(\n",
    "                [{\"params\": encoder.parameters()}, {\"params\": decoder.parameters()}],\n",
    "                lr=cfg.TRAIN.BASE_LEARNING_RATE,\n",
    "                betas=(cfg.TRAIN.ADAM_BETA_0, cfg.TRAIN.ADAM_BETA_1),\n",
    "                weight_decay=0,\n",
    "            )\n",
    "    model_dict = {\n",
    "        \"encoder\": encoder,\n",
    "        \"generator\": decoder,\n",
    "    }\n",
    "    if hasattr(model, \"ecog_encoder\"):\n",
    "        model_dict[\"ecog_encoder\"] = ecog_encoder\n",
    "    if hasattr(model, \"decoder_mel\"):\n",
    "        model_dict[\"decoder_mel\"] = decoder_mel\n",
    "    if local_rank == 0:\n",
    "        model_dict[\"encoder_s\"] = model_s.encoder.to(device)\n",
    "        model_dict[\"generator_s\"] = model_s.decoder.to(device)\n",
    "        if hasattr(model_s, \"ecog_encoder\"):\n",
    "            model_dict[\"ecog_encoder_s\"] = model_s.ecog_encoder.to(device)\n",
    "        if hasattr(model_s, \"decoder_mel\"):\n",
    "            model_dict[\"decoder_mel_s\"] = model_s.decoder_mel\n",
    "    noise_dist = torch.from_numpy(dataset_all[subject].noise_dist).to(device).float()\n",
    "    if cfg.MODEL.BGNOISE_FROMDATA:\n",
    "        model_s.noise_dist_init(noise_dist)\n",
    "        model.noise_dist_init(noise_dist)\n",
    "    if cfg.MODEL.ECOG:\n",
    "        if cfg.MODEL.SUPLOSS_ON_ECOGF:\n",
    "            optimizer = LREQAdam(\n",
    "                [{\"params\": ecog_encoder.parameters()}],\n",
    "                lr=cfg.TRAIN.BASE_LEARNING_RATE,\n",
    "                betas=(cfg.TRAIN.ADAM_BETA_0, cfg.TRAIN.ADAM_BETA_1),\n",
    "                weight_decay=0,\n",
    "            )\n",
    "        else:\n",
    "            optimizer = LREQAdam(\n",
    "                [\n",
    "                    {\"params\": ecog_encoder.parameters()},\n",
    "                    {\"params\": decoder.parameters()},\n",
    "                ],\n",
    "                lr=cfg.TRAIN.BASE_LEARNING_RATE,\n",
    "                betas=(cfg.TRAIN.ADAM_BETA_0, cfg.TRAIN.ADAM_BETA_1),\n",
    "                weight_decay=0,\n",
    "            )\n",
    "    else:\n",
    "        if cfg.MODEL.DO_MEL_GUIDE:\n",
    "            optimizer = LREQAdam(\n",
    "                [\n",
    "                    {\"params\": encoder.parameters()},\n",
    "                    {\"params\": decoder.parameters()},\n",
    "                    {\"params\": decoder_mel.parameters()},\n",
    "                ],\n",
    "                lr=cfg.TRAIN.BASE_LEARNING_RATE,\n",
    "                betas=(cfg.TRAIN.ADAM_BETA_0, cfg.TRAIN.ADAM_BETA_1),\n",
    "                weight_decay=0,\n",
    "            )\n",
    "        else:\n",
    "            optimizer = LREQAdam(\n",
    "                [\n",
    "                    {\"params\": encoder.parameters()},\n",
    "                    {\"params\": decoder.parameters()},\n",
    "                ],\n",
    "                lr=cfg.TRAIN.BASE_LEARNING_RATE,\n",
    "                betas=(cfg.TRAIN.ADAM_BETA_0, cfg.TRAIN.ADAM_BETA_1),\n",
    "                weight_decay=0,\n",
    "            )\n",
    "    tracker = LossTracker(cfg.OUTPUT_DIR)\n",
    "    tracker_test = LossTracker(cfg.OUTPUT_DIR, test=True)\n",
    "    auxiliary = {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"tracker\": tracker,\n",
    "        \"tracker_test\": tracker_test,\n",
    "    }\n",
    "    checkpointer = Checkpointer(\n",
    "        cfg, model_dict, auxiliary, logger=logger, save=local_rank == 0\n",
    "    )\n",
    "    if LOAD:\n",
    "        extra_checkpoint_data = checkpointer.load(\n",
    "            ignore_last_checkpoint=True if LOAD!=0 else False,\n",
    "            ignore_auxiliary=True,\n",
    "            file_name=load_dir,\n",
    "        )\n",
    "        arguments.update(extra_checkpoint_data)\n",
    "    return (\n",
    "        checkpointer,\n",
    "        model,\n",
    "        model_s,\n",
    "        encoder,\n",
    "        decoder,\n",
    "        ecog_encoder,\n",
    "        optimizer,\n",
    "        tracker,\n",
    "        tracker_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(cfg, logger, local_rank, world_size, distributed):\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.set_device(local_rank)\n",
    "    with open('configs/train_param_production.json', 'r') as stream:\n",
    "        param = json.load(stream)\n",
    "    dataset_all, dataset_test_all = {}, {}\n",
    "    train_subject_info = args_.trainsubject.split(\",\") if args_.trainsubject != \"\" else cfg.DATASET.SUBJECT \n",
    "    test_subject_info = args_.testsubject.split(\",\") if args_.testsubject != \"\" else cfg.DATASET.SUBJECT\n",
    "\n",
    "    for subject in np.union1d(train_subject_info, test_subject_info):\n",
    "        dataset_all[subject] = TFRecordsDataset(\n",
    "            cfg,\n",
    "            logger,\n",
    "            rank=local_rank,\n",
    "            world_size=world_size,\n",
    "            SUBJECT=[subject],\n",
    "            buffer_size_mb=1024,\n",
    "            channels=cfg.MODEL.CHANNELS,\n",
    "            param=param,\n",
    "            allsubj_param=allsubj_param,\n",
    "            ReshapeAsGrid=1,\n",
    "            rearrange_elec=0,\n",
    "            low_density=cfg.DATASET.DENSITY == \"LD\",\n",
    "            process_ecog=True,\n",
    "        )\n",
    "\n",
    "    for subject in test_subject_info:\n",
    "        dataset_test_all[subject] = TFRecordsDataset(\n",
    "            cfg,\n",
    "            logger,\n",
    "            rank=local_rank,\n",
    "            world_size=world_size,\n",
    "            SUBJECT=[subject],\n",
    "            buffer_size_mb=1024,\n",
    "            channels=cfg.MODEL.CHANNELS,\n",
    "            train=False,\n",
    "            param=param,\n",
    "            allsubj_param=allsubj_param,\n",
    "            ReshapeAsGrid=1,\n",
    "            rearrange_elec=0,\n",
    "            low_density=cfg.DATASET.DENSITY == \"LD\",\n",
    "            process_ecog=True,\n",
    "        )\n",
    "    tracker = LossTracker(cfg.OUTPUT_DIR)\n",
    "    tracker_test = LossTracker(cfg.OUTPUT_DIR, test=True)\n",
    "\n",
    "    (checkpointer_all,\n",
    "        model_all,\n",
    "        model_s_all,\n",
    "        encoder_all,\n",
    "        decoder_all,\n",
    "        ecog_encoder_all,\n",
    "        optimizer_all,\n",
    "    ) = ({}, {}, {}, {}, {}, {}, {})\n",
    "\n",
    "    for single_patient_mapping, subject in enumerate(\n",
    "        np.union1d(train_subject_info, test_subject_info)\n",
    "    ): \n",
    "        if args_.pretrained_model_dir != \"\":\n",
    "            load_sub_dir = args_.pretrained_model_dir\n",
    "            max_epoch = (\n",
    "                np.array(\n",
    "                    [\n",
    "                        i.split('epoch')[1].split('.pth')[0]\n",
    "                        for i in os.listdir(load_sub_dir)\n",
    "                        if i.endswith(\"pth\")\n",
    "                    ]\n",
    "                )\n",
    "                .astype(\"int\")\n",
    "                .max()\n",
    "            )\n",
    "            load_sub_name = [i for i in load_sub_dir.split(\"/\") if \"NY\" in i][0]\n",
    "            print(\"subject, load_sub_name\", subject, load_sub_name)\n",
    "            load_sub_dir = load_sub_dir + \"/{}_a2a_model_epoch{}.pth\".format(\n",
    "                   load_sub_name, max_epoch  \n",
    "                )\n",
    "            print(\"pretrained load dir\", load_sub_dir)\n",
    "        else:\n",
    "            load_sub_dir = ''\n",
    "            print ('No pretrainde a2a model provided!')\n",
    "            #raise Exception(\"Please Provide pretrained_model_dir\")\n",
    "        (\n",
    "            checkpointer_all[subject],\n",
    "            model_all[subject],\n",
    "            model_s_all[subject],\n",
    "            encoder_all[subject],\n",
    "            decoder_all[subject],\n",
    "            ecog_encoder_all[subject],\n",
    "            optimizer_all[subject],\n",
    "            tracker,\n",
    "            tracker_test,\n",
    "        ) = load_model_checkpoint(\n",
    "            logger,\n",
    "            local_rank,\n",
    "            distributed,\n",
    "            tracker=tracker,\n",
    "            tracker_test=tracker_test,\n",
    "            dataset_all=dataset_all,\n",
    "            subject=subject,\n",
    "            load_dir=load_sub_dir,\n",
    "            single_patient_mapping=single_patient_mapping,param=param\n",
    "        )\n",
    "    loadsub = train_subject_info[0]\n",
    "    ecog_encoder_shared = ecog_encoder_all[loadsub]\n",
    "\n",
    "    for single_patient_mapping, subject in enumerate(\n",
    "        np.union1d(train_subject_info, test_subject_info)\n",
    "    ):\n",
    "        model_all[\n",
    "            subject\n",
    "        ].ecog_encoder = ecog_encoder_shared\n",
    "        model_s_all[\n",
    "            subject\n",
    "        ].ecog_encoder = ecog_encoder_shared\n",
    "    (   \n",
    "        ecog_test_all,\n",
    "        sample_wave_test_all,\n",
    "        sample_spec_test_all,\n",
    "        sample_spec_amp_test_all,\n",
    "        sample_label_test_all,\n",
    "        gender_test_all,\n",
    "        on_stage_test_all,\n",
    "        on_stage_wider_test_all,\n",
    "    ) = (\n",
    "        {},{},{},{},{},{},{},{})\n",
    "\n",
    "    hann_win = torch.hann_window(21, periodic=False).reshape([1, 1, 21, 1])\n",
    "    hann_win = hann_win / hann_win.sum()\n",
    "    x_amp_from_denoise = False\n",
    "\n",
    "    for subject in test_subject_info:\n",
    "        dataset_test_all[subject].reset(\n",
    "            cfg.DATASET.MAX_RESOLUTION_LEVEL, len(dataset_test_all[subject].dataset)\n",
    "        )\n",
    "        sample_dict_test = next(iter(dataset_test_all[subject].iterator))\n",
    "        gender_test_all[subject] = sample_dict_test['gender_all'].to(device).float()\n",
    "        if cfg.DATASET.PROD:\n",
    "            sample_wave_test_all[subject] = (\n",
    "                sample_dict_test[\"wave_re_batch_all\"].to(device).float()\n",
    "            )\n",
    "            if cfg.MODEL.WAVE_BASED:\n",
    "                sample_spec_test_all[subject] = (\n",
    "                    sample_dict_test[\"wave_spec_re_batch_all\"].to(device).float()\n",
    "                )\n",
    "                sample_spec_amp_test_all[subject] = (\n",
    "                    sample_dict_test[\"wave_spec_re_amp_batch_all\"]\n",
    "                    .to(device)\n",
    "                    .float()\n",
    "                )\n",
    "            sample_label_test_all[subject] = sample_dict_test[\"label_batch_all\"]\n",
    "            if cfg.MODEL.ECOG:\n",
    "                ecog_test_all[subject] = sample_dict_test[\"ecog_re_batch_all\"].to(device).float()\n",
    "            on_stage_test_all[subject] = (\n",
    "                sample_dict_test[\"on_stage_re_batch_all\"].to(device).float()\n",
    "            )\n",
    "            on_stage_wider_test_all[subject] = (\n",
    "                sample_dict_test[\"on_stage_wider_re_batch_all\"].to(device).float()\n",
    "            )\n",
    "    duomask = True\n",
    "    x_amp_from_denoise = False\n",
    "    n_iter = 0\n",
    "\n",
    "    (\n",
    "        ecog_all,\n",
    "        wave_orig_all,\n",
    "        x_orig_all,\n",
    "        x_orig_amp_all,\n",
    "        labels_all,\n",
    "        gender_train_all,\n",
    "        on_stage_all,\n",
    "        on_stage_wider_all\n",
    "    ) = (\n",
    "        {},{},{},{},{},{},{},{}\n",
    "    )\n",
    "    for epoch in tqdm(range(cfg.TRAIN.TRAIN_EPOCHS)):\n",
    "        \n",
    "        \n",
    "        #train\n",
    "        for subject in train_subject_info:\n",
    "            model_all[subject].train()\n",
    "        i = 0\n",
    "        dataset_iterator_all = {}\n",
    "        if len(train_subject_info) <= 1:\n",
    "            dataset_iterator_all[train_subject_info[0]] = iter(\n",
    "                dataset_all[train_subject_info[0]].iterator\n",
    "            )\n",
    "            sample_dict_train_all = {}\n",
    "            for sample_dict_train_all[train_subject_info[0]] in tqdm(\n",
    "                dataset_iterator_all[train_subject_info[0]]\n",
    "            ):\n",
    "                n_iter += 1\n",
    "                i += 1\n",
    "                for subject in train_subject_info:\n",
    "                    if n_iter % 200 == 0:\n",
    "                        print(tracker.register_means(n_iter))\n",
    "                    (\n",
    "                        ecog_all,\n",
    "                        wave_orig_all,\n",
    "                        x_orig_all,\n",
    "                        x_orig_amp_all,\n",
    "                        labels_all,\n",
    "                        gender_train_all,\n",
    "                        on_stage_all,\n",
    "                        on_stage_wider_all\n",
    "                    ) = get_train_data(\n",
    "                        ecog_all,\n",
    "                        wave_orig_all,\n",
    "                        x_orig_all,\n",
    "                        x_orig_amp_all,\n",
    "                        labels_all,\n",
    "                        gender_train_all,\n",
    "                        on_stage_all,\n",
    "                        on_stage_wider_all,\n",
    "                        sample_dict_train_all[train_subject_info[0]],\n",
    "                        subject=subject,\n",
    "                    )\n",
    "                    initial = None\n",
    "                    \n",
    "                    optimizer_all[subject].zero_grad()\n",
    "                    Lrec, tracker = model_all[subject](\n",
    "                        x_orig_all[subject],\n",
    "                        ecog=ecog_all[subject],\n",
    "                        on_stage=on_stage_all[subject],\n",
    "                        on_stage_wider=on_stage_all[subject],\n",
    "                        ae=False,\n",
    "                        tracker=tracker,\n",
    "                        encoder_guide=cfg.MODEL.W_SUP,\n",
    "                        duomask=duomask,\n",
    "                        x_amp=x_orig_amp_all[subject],\n",
    "                        x_amp_from_denoise=x_amp_from_denoise,\n",
    "                        gender=gender_train_all[subject],\n",
    "                    )\n",
    "                    (Lrec).backward()\n",
    "                    optimizer_all[subject].step()\n",
    "\n",
    "                    betta = 0.5 ** (cfg.TRAIN.BATCH_SIZE / (10 * 1000.0))\n",
    "                    model_s_all[subject].lerp(\n",
    "                        model_all[subject],\n",
    "                        betta,\n",
    "                        w_classifier=cfg.MODEL.W_CLASSIFIER,\n",
    "                    )\n",
    "\n",
    "        #test\n",
    "        for subject in test_subject_info:\n",
    "            print(\n",
    "                2\n",
    "                ** (\n",
    "                    torch.tanh(\n",
    "                        model_all[subject].encoder.formant_bandwitdh_slop\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "            print(\"save test result!\")\n",
    "\n",
    "            model_all[subject].eval()\n",
    "            Lrec = model_all[subject](\n",
    "                sample_spec_test_all[subject],\n",
    "                x_denoise=None,\n",
    "                x_mel=None,\n",
    "                ecog=ecog_test_all[subject] if cfg.MODEL.ECOG else None,\n",
    "                on_stage=on_stage_test_all[subject],\n",
    "                ae=not cfg.MODEL.ECOG,\n",
    "                tracker=tracker_test,\n",
    "                encoder_guide=cfg.MODEL.W_SUP,\n",
    "                pitch_aug=False,\n",
    "                duomask=duomask,\n",
    "                debug=False,\n",
    "                x_amp=sample_spec_amp_test_all[subject],\n",
    "                hamonic_bias=False,\n",
    "                gender=gender_test_all[subject],\n",
    "                on_stage_wider=on_stage_test_all[subject],\n",
    "            )\n",
    "\n",
    "            initial = None\n",
    "\n",
    "            if epoch % 1 == 0:\n",
    "                checkpointer_all[subject].save(\n",
    "                    \"model_epoch{}_{}\".format(epoch, subject)\n",
    "                )\n",
    "                save_sample(\n",
    "                    cfg,\n",
    "                    sample_spec_test_all[subject],\n",
    "                    ecog_test_all[subject],\n",
    "                    encoder_all[subject],\n",
    "                    decoder_all[subject],\n",
    "                    ecog_encoder_shared\n",
    "                    if hasattr(model_all[subject], \"ecog_encoder\")\n",
    "                    else None,\n",
    "                    encoder2\n",
    "                    if hasattr(model_all[subject], \"encoder2\")\n",
    "                    else None,\n",
    "                    x_denoise=None,\n",
    "                    decoder_mel=decoder_mel if cfg.MODEL.DO_MEL_GUIDE else None,\n",
    "                    epoch=epoch,\n",
    "                    label=sample_label_test_all[subject],\n",
    "                    mode=\"test\",\n",
    "                    path=cfg.OUTPUT_DIR,\n",
    "                    tracker=tracker_test,\n",
    "                    linear=cfg.MODEL.WAVE_BASED,\n",
    "                    n_fft=cfg.MODEL.N_FFT,\n",
    "                    duomask=duomask,\n",
    "                    x_amp=sample_spec_amp_test_all[subject],\n",
    "                    gender=gender_test_all[subject],\n",
    "                    sample_wave=sample_wave_test_all[subject],\n",
    "                    sample_wave_denoise=None,\n",
    "                    on_stage_wider=on_stage_test_all[subject],\n",
    "                    auto_regressive=False,\n",
    "                    seq_out_start=initial,\n",
    "                    suffix=subject,\n",
    "                )\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gpu_count = torch.cuda.device_count()\n",
    "cfg = get_cfg_defaults()\n",
    "if args_.trainsubject != \"\":\n",
    "    train_subject_info = args_.trainsubject.split(\",\")\n",
    "else:\n",
    "    train_subject_info = cfg.DATASET.SUBJECT\n",
    "if args_.testsubject != \"\":\n",
    "    test_subject_info = args_.testsubject.split(\",\")\n",
    "else:\n",
    "    test_subject_info = cfg.DATASET.SUBJECT\n",
    "with open(\"configs/AllSubjectInfo.json\", \"r\") as rfile:\n",
    "    allsubj_param = json.load(rfile)\n",
    "subj_param = allsubj_param[\"Subj\"][args_.trainsubject.split(\",\")[0]]\n",
    "Gender = subj_param[\"Gender\"] if cfg.DATASET.PROD else \"Female\"\n",
    "config_file = args_.param_file\n",
    "cfg.merge_from_file(config_file)\n",
    "args_.config_file = config_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank in _run 0\n",
      "2023-06-11 00:17:42,576 logger INFO: <__main__.Args object at 0x14c7020cc850>\n",
      "2023-06-11 00:17:42,579 logger INFO: World size: 1\n",
      "2023-06-11 00:17:42,580 logger INFO: Loaded configuration file configs/e2a_production.yaml\n",
      "TestNum_cum 1\n",
      "ecog_alldataset 1\n",
      "end_ind_re_valid_alldataset 1\n",
      "formant_re_alldataset 1\n",
      "intensity_re_alldataset 1\n",
      "label_alldataset 1\n",
      "noisesample_re_alldataset 1\n",
      "pitch_re_alldataset 1\n",
      "start_ind_re_valid_alldataset 1\n",
      "wave_re_alldataset 1\n",
      "wave_re_spec_alldataset 1\n",
      "wave_re_spec_amp_alldataset 1\n",
      "self.meta_data[ TestNum_cum s] [50]\n",
      "dict_keys(['TestNum_cum', 'ecog_alldataset', 'end_ind_re_valid_alldataset', 'formant_re_alldataset', 'intensity_re_alldataset', 'label_alldataset', 'noisesample_re_alldataset', 'pitch_re_alldataset', 'start_ind_re_valid_alldataset', 'wave_re_alldataset', 'wave_re_spec_alldataset', 'wave_re_spec_amp_alldataset'])\n",
      "self.ReshapeAsGrid:  1 ECoGMapping_ResNet\n",
      "dict_keys(['TestNum_cum', 'ecog_alldataset', 'end_ind_re_valid_alldataset', 'formant_re_alldataset', 'intensity_re_alldataset', 'label_alldataset', 'noisesample_re_alldataset', 'pitch_re_alldataset', 'start_ind_re_valid_alldataset', 'wave_re_alldataset', 'wave_re_spec_alldataset', 'wave_re_spec_amp_alldataset', 'gender_alldataset'])\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "TestNum_cum 1\n",
      "ecog_alldataset 1\n",
      "end_ind_re_valid_alldataset 1\n",
      "formant_re_alldataset 1\n",
      "intensity_re_alldataset 1\n",
      "label_alldataset 1\n",
      "noisesample_re_alldataset 1\n",
      "pitch_re_alldataset 1\n",
      "start_ind_re_valid_alldataset 1\n",
      "wave_re_alldataset 1\n",
      "wave_re_spec_alldataset 1\n",
      "wave_re_spec_amp_alldataset 1\n",
      "self.meta_data[ TestNum_cum s] [50]\n",
      "dict_keys(['TestNum_cum', 'ecog_alldataset', 'end_ind_re_valid_alldataset', 'formant_re_alldataset', 'intensity_re_alldataset', 'label_alldataset', 'noisesample_re_alldataset', 'pitch_re_alldataset', 'start_ind_re_valid_alldataset', 'wave_re_alldataset', 'wave_re_spec_alldataset', 'wave_re_spec_amp_alldataset'])\n",
      "self.ReshapeAsGrid:  1 ECoGMapping_ResNet\n",
      "dict_keys(['TestNum_cum', 'ecog_alldataset', 'end_ind_re_valid_alldataset', 'formant_re_alldataset', 'intensity_re_alldataset', 'label_alldataset', 'noisesample_re_alldataset', 'pitch_re_alldataset', 'start_ind_re_valid_alldataset', 'wave_re_alldataset', 'wave_re_spec_alldataset', 'wave_re_spec_amp_alldataset', 'gender_alldataset'])\n",
      "length, self.TestNum_cum [50]\n",
      "subject, load_sub_name NY869 NY869\n",
      "pretrained load dir output/a2a/NY869/NY869_a2a_model_epoch95.pth\n",
      "component_regression False\n",
      "patient in model NY869\n",
      "patient for audio encoder: NY869\n",
      "gender_patient Male\n",
      "encoder loudness, 512\n",
      "self.noise_db,self.max_db -50 22.5\n",
      "component_regression False\n",
      "patient in model NY869\n",
      "patient for audio encoder: NY869\n",
      "gender_patient Male\n",
      "encoder loudness, 512\n",
      "self.noise_db,self.max_db -50 22.5\n",
      "2023-06-11 00:17:42,722 logger INFO: Trainable parameters generator:\n",
      "2023-06-11 00:17:42,724 logger INFO: Trainable parameters discriminator:\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/47 [00:02<01:45,  2.29s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:04<01:38,  2.18s/it]\u001b[A\n",
      "  6%|▋         | 3/47 [00:06<01:33,  2.13s/it]\u001b[A\n",
      "  9%|▊         | 4/47 [00:08<01:33,  2.17s/it]\u001b[A\n",
      " 11%|█         | 5/47 [00:10<01:28,  2.10s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:12<01:24,  2.06s/it]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:14<01:22,  2.06s/it]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:16<01:18,  2.02s/it]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:18<01:15,  1.99s/it]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:20<01:11,  1.93s/it]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:22<01:09,  1.94s/it]\u001b[A\n",
      " 26%|██▌       | 12/47 [00:24<01:08,  1.95s/it]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:26<01:07,  1.99s/it]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:28<01:05,  1.99s/it]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:30<01:02,  1.96s/it]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:32<01:01,  1.97s/it]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:34<00:59,  1.98s/it]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:36<00:56,  1.96s/it]\u001b[A\n",
      " 40%|████      | 19/47 [00:38<00:54,  1.96s/it]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:40<00:55,  2.04s/it]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:42<00:52,  2.01s/it]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:44<00:49,  2.00s/it]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:46<00:47,  1.98s/it]\u001b[A\n",
      " 51%|█████     | 24/47 [00:48<00:45,  1.98s/it]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:50<00:43,  1.98s/it]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:52<00:42,  2.00s/it]\u001b[A\n",
      " 57%|█████▋    | 27/47 [00:54<00:39,  1.99s/it]\u001b[A\n",
      " 60%|█████▉    | 28/47 [00:56<00:38,  2.01s/it]\u001b[A\n",
      " 62%|██████▏   | 29/47 [00:58<00:35,  1.99s/it]\u001b[A\n",
      " 64%|██████▍   | 30/47 [01:00<00:33,  1.97s/it]\u001b[A\n",
      " 66%|██████▌   | 31/47 [01:02<00:31,  1.94s/it]\u001b[A\n",
      " 68%|██████▊   | 32/47 [01:03<00:29,  1.94s/it]\u001b[A\n",
      " 70%|███████   | 33/47 [01:05<00:27,  1.95s/it]\u001b[A\n",
      " 72%|███████▏  | 34/47 [01:07<00:25,  1.94s/it]\u001b[A\n",
      " 74%|███████▍  | 35/47 [01:09<00:23,  1.93s/it]\u001b[A\n",
      " 77%|███████▋  | 36/47 [01:11<00:21,  1.93s/it]\u001b[A\n",
      " 79%|███████▊  | 37/47 [01:13<00:19,  1.94s/it]\u001b[A\n",
      " 81%|████████  | 38/47 [01:15<00:17,  1.97s/it]\u001b[A\n",
      " 83%|████████▎ | 39/47 [01:17<00:15,  2.00s/it]\u001b[A\n",
      " 85%|████████▌ | 40/47 [01:19<00:14,  2.01s/it]\u001b[A\n",
      " 87%|████████▋ | 41/47 [01:21<00:11,  1.99s/it]\u001b[A\n",
      " 89%|████████▉ | 42/47 [01:23<00:09,  1.96s/it]\u001b[A\n",
      " 91%|█████████▏| 43/47 [01:25<00:07,  1.94s/it]\u001b[A\n",
      " 94%|█████████▎| 44/47 [01:27<00:05,  1.90s/it]\u001b[A\n",
      " 96%|█████████▌| 45/47 [01:29<00:03,  1.93s/it]\u001b[A\n",
      " 98%|█████████▊| 46/47 [01:31<00:01,  1.96s/it]\u001b[A\n",
      "100%|██████████| 47/47 [01:33<00:00,  1.98s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "tensor([1.])\n",
      "save test result!\n",
      "2023-06-11 00:19:21,759 logger INFO: Saving checkpoint to output/resnet/model_epoch0_NY869.pth\n",
      "registering means,n_iter,self.n_iters 0 []\n",
      "0 Lae_a1 0.0\n",
      "0 Lae_a_l21 0.0\n",
      "0 Lae_db1 0.2677802\n",
      "0 Lae_db_l21 0.267818\n",
      "0 Lae_a2 0.0\n",
      "0 Lae_a_l22 0.0\n",
      "0 Lae_db2 0.26032233\n",
      "0 Lae_db_l22 0.26033404\n",
      "0 Lrec 21.124102\n",
      "0 loudness_metric 0.015242103\n",
      "0 loudness 4.00646\n",
      "0 f0_metric 1.9358493\n",
      "0 f0_hz 0.5807548\n",
      "0 amplitudes_metric 0.013717631\n",
      "0 amplitudes 6.700783\n",
      "0 amplitude_formants_hamon_metric 0.0007394142\n",
      "0 amplitude_formants_hamon 0.29576567\n",
      "0 freq_formants_hamon_hz_metric_2 0.11886589\n",
      "0 freq_formants_hamon_hz_metric_6 0.1609572\n",
      "0 freq_formants_hamon 0.37046427\n",
      "0 amplitude_formants_noise_metric 0.0019222703\n",
      "0 amplitude_formants_noise 0.76890814\n",
      "0 freq_formants_noise_metric 0.4208961\n",
      "0 freq_formants_noise 1.9831544\n",
      "0 bandwidth_formants_noise_hz_metric 2.548035\n",
      "0 bandwidth_formants_noise_hz 7.644105\n",
      "0 Ldiff 0.04359938\n",
      "0 Lexp -0.16299137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [03:34<5:54:23, 214.78s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/47 [00:02<01:37,  2.12s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:04<01:34,  2.09s/it]\u001b[A\n",
      "  6%|▋         | 3/47 [00:06<01:31,  2.07s/it]\u001b[A\n",
      "  9%|▊         | 4/47 [00:08<01:29,  2.08s/it]\u001b[A\n",
      " 11%|█         | 5/47 [00:10<01:26,  2.06s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:12<01:22,  2.02s/it]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:14<01:19,  1.99s/it]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:16<01:16,  1.95s/it]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:17<01:12,  1.92s/it]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:19<01:10,  1.91s/it]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:21<01:09,  1.92s/it]\u001b[A\n",
      " 26%|██▌       | 12/47 [00:23<01:07,  1.92s/it]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:25<01:05,  1.91s/it]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:27<01:03,  1.94s/it]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:29<01:01,  1.93s/it]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:31<00:59,  1.93s/it]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:33<00:58,  1.95s/it]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:35<00:55,  1.92s/it]\u001b[A\n",
      " 40%|████      | 19/47 [00:37<00:52,  1.88s/it]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:39<00:51,  1.91s/it]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:40<00:48,  1.87s/it]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:42<00:47,  1.90s/it]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:44<00:46,  1.92s/it]\u001b[A\n",
      " 51%|█████     | 24/47 [00:46<00:43,  1.90s/it]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:48<00:41,  1.90s/it]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:50<00:39,  1.90s/it]\u001b[A\n",
      " 57%|█████▋    | 27/47 [00:52<00:38,  1.92s/it]\u001b[A\n",
      " 60%|█████▉    | 28/47 [00:54<00:35,  1.89s/it]\u001b[A\n",
      " 62%|██████▏   | 29/47 [00:56<00:33,  1.87s/it]\u001b[A\n",
      " 64%|██████▍   | 30/47 [00:57<00:32,  1.89s/it]\u001b[A\n",
      " 66%|██████▌   | 31/47 [00:59<00:30,  1.89s/it]\u001b[A\n",
      " 68%|██████▊   | 32/47 [01:01<00:28,  1.88s/it]\u001b[A\n",
      " 70%|███████   | 33/47 [01:03<00:26,  1.88s/it]\u001b[A\n",
      " 72%|███████▏  | 34/47 [01:05<00:24,  1.88s/it]\u001b[A\n",
      " 74%|███████▍  | 35/47 [01:07<00:22,  1.84s/it]\u001b[A\n",
      " 77%|███████▋  | 36/47 [01:09<00:20,  1.85s/it]\u001b[A\n",
      " 79%|███████▊  | 37/47 [01:11<00:18,  1.90s/it]\u001b[A\n",
      " 81%|████████  | 38/47 [01:12<00:16,  1.89s/it]\u001b[A\n",
      " 83%|████████▎ | 39/47 [01:14<00:14,  1.86s/it]\u001b[A\n",
      " 85%|████████▌ | 40/47 [01:16<00:13,  1.87s/it]\u001b[A\n",
      " 87%|████████▋ | 41/47 [01:18<00:11,  1.86s/it]\u001b[A\n",
      " 89%|████████▉ | 42/47 [01:20<00:09,  1.87s/it]\u001b[A\n",
      " 91%|█████████▏| 43/47 [01:22<00:07,  1.90s/it]\u001b[A\n",
      " 94%|█████████▎| 44/47 [01:24<00:05,  1.88s/it]\u001b[A\n",
      " 96%|█████████▌| 45/47 [01:26<00:03,  1.88s/it]\u001b[A\n",
      " 98%|█████████▊| 46/47 [01:27<00:01,  1.90s/it]\u001b[A\n",
      "100%|██████████| 47/47 [01:29<00:00,  1.91s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "tensor([1.])\n",
      "save test result!\n",
      "2023-06-11 00:22:53,088 logger INFO: Saving checkpoint to output/resnet/model_epoch1_NY869.pth\n",
      "registering means,n_iter,self.n_iters 1 [0]\n",
      "1 Lae_a1 0.0\n",
      "1 Lae_a_l21 0.0\n",
      "1 Lae_db1 0.26282498\n",
      "1 Lae_db_l21 0.26286075\n",
      "1 Lae_a2 0.0\n",
      "1 Lae_a_l22 0.0\n",
      "1 Lae_db2 0.25013015\n",
      "1 Lae_db_l22 0.25014192\n",
      "1 Lrec 20.518206\n",
      "1 loudness_metric 0.015204156\n",
      "1 loudness 3.9717407\n",
      "1 f0_metric 0.32003784\n",
      "1 f0_hz 0.096011356\n",
      "1 amplitudes_metric 0.012421683\n",
      "1 amplitudes 6.7395463\n",
      "1 amplitude_formants_hamon_metric 0.000703727\n",
      "1 amplitude_formants_hamon 0.2814908\n",
      "1 freq_formants_hamon_hz_metric_2 0.08216901\n",
      "1 freq_formants_hamon_hz_metric_6 0.11941582\n",
      "1 freq_formants_hamon 0.24883237\n",
      "1 amplitude_formants_noise_metric 0.0017236979\n",
      "1 amplitude_formants_noise 0.6894792\n",
      "1 freq_formants_noise_metric 0.3423767\n",
      "1 freq_formants_noise 1.6101981\n",
      "1 bandwidth_formants_noise_hz_metric 2.4412599\n",
      "1 bandwidth_formants_noise_hz 7.3237796\n",
      "1 Ldiff 0.03959763\n",
      "1 Lexp -0.1582362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [07:06<5:48:19, 213.26s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/47 [00:02<01:39,  2.16s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:04<01:30,  2.01s/it]\u001b[A\n",
      "  6%|▋         | 3/47 [00:05<01:24,  1.93s/it]\u001b[A\n",
      "  9%|▊         | 4/47 [00:07<01:22,  1.91s/it]\u001b[A\n",
      " 11%|█         | 5/47 [00:09<01:18,  1.88s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:11<01:17,  1.88s/it]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:13<01:15,  1.89s/it]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:15<01:13,  1.88s/it]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:17<01:11,  1.89s/it]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:18<01:09,  1.87s/it]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:20<01:08,  1.90s/it]\u001b[A\n",
      " 26%|██▌       | 12/47 [00:22<01:06,  1.89s/it]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:24<01:05,  1.93s/it]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:26<01:02,  1.90s/it]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:28<01:00,  1.90s/it]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:30<01:00,  1.94s/it]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:32<00:58,  1.94s/it]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:34<00:55,  1.91s/it]\u001b[A\n",
      " 40%|████      | 19/47 [00:36<00:53,  1.92s/it]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:38<00:51,  1.90s/it]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:40<00:49,  1.90s/it]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:42<00:48,  1.94s/it]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:43<00:45,  1.91s/it]\u001b[A\n",
      " 51%|█████     | 24/47 [00:45<00:43,  1.89s/it]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:47<00:41,  1.88s/it]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:49<00:40,  1.92s/it]\u001b[A\n",
      " 57%|█████▋    | 27/47 [00:51<00:38,  1.93s/it]\u001b[A\n",
      " 60%|█████▉    | 28/47 [00:53<00:36,  1.93s/it]\u001b[A\n",
      " 62%|██████▏   | 29/47 [00:55<00:34,  1.94s/it]\u001b[A\n",
      " 64%|██████▍   | 30/47 [00:57<00:32,  1.94s/it]\u001b[A\n",
      " 66%|██████▌   | 31/47 [00:59<00:30,  1.93s/it]\u001b[A\n",
      " 68%|██████▊   | 32/47 [01:01<00:29,  1.94s/it]\u001b[A\n",
      " 70%|███████   | 33/47 [01:03<00:26,  1.92s/it]\u001b[A\n",
      " 72%|███████▏  | 34/47 [01:04<00:24,  1.88s/it]\u001b[A\n",
      " 74%|███████▍  | 35/47 [01:06<00:22,  1.85s/it]\u001b[A\n",
      " 77%|███████▋  | 36/47 [01:08<00:20,  1.85s/it]\u001b[A\n",
      " 79%|███████▊  | 37/47 [01:10<00:18,  1.84s/it]\u001b[A\n",
      " 81%|████████  | 38/47 [01:12<00:16,  1.87s/it]\u001b[A\n",
      " 83%|████████▎ | 39/47 [01:14<00:14,  1.83s/it]\u001b[A\n",
      " 85%|████████▌ | 40/47 [01:15<00:12,  1.83s/it]\u001b[A\n",
      " 87%|████████▋ | 41/47 [01:17<00:11,  1.87s/it]\u001b[A\n",
      " 89%|████████▉ | 42/47 [01:19<00:09,  1.89s/it]\u001b[A\n",
      " 91%|█████████▏| 43/47 [01:21<00:07,  1.88s/it]\u001b[A\n",
      " 94%|█████████▎| 44/47 [01:23<00:05,  1.88s/it]\u001b[A\n",
      " 96%|█████████▌| 45/47 [01:25<00:03,  1.89s/it]\u001b[A\n",
      " 98%|█████████▊| 46/47 [01:27<00:01,  1.89s/it]\u001b[A\n",
      "100%|██████████| 47/47 [01:29<00:00,  1.90s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "tensor([1.])\n",
      "save test result!\n",
      "2023-06-11 00:26:24,626 logger INFO: Saving checkpoint to output/resnet/model_epoch2_NY869.pth\n",
      "registering means,n_iter,self.n_iters 2 [0, 1]\n",
      "2 Lae_a1 0.0\n",
      "2 Lae_a_l21 0.0\n",
      "2 Lae_db1 0.25020963\n",
      "2 Lae_db_l21 0.25024873\n",
      "2 Lae_a2 0.0\n",
      "2 Lae_a_l22 0.0\n",
      "2 Lae_db2 0.2423929\n",
      "2 Lae_db_l22 0.24240509\n",
      "2 Lrec 19.704102\n",
      "2 loudness_metric 0.014805636\n",
      "2 loudness 3.8310122\n",
      "2 f0_metric 0.07176988\n",
      "2 f0_hz 0.021530963\n",
      "2 amplitudes_metric 0.011415317\n",
      "2 amplitudes 6.524787\n",
      "2 amplitude_formants_hamon_metric 0.0006941898\n",
      "2 amplitude_formants_hamon 0.27767593\n",
      "2 freq_formants_hamon_hz_metric_2 0.056592673\n",
      "2 freq_formants_hamon_hz_metric_6 0.0981735\n",
      "2 freq_formants_hamon 0.1747631\n",
      "2 amplitude_formants_noise_metric 0.001883906\n",
      "2 amplitude_formants_noise 0.7535624\n",
      "2 freq_formants_noise_metric 0.36421186\n",
      "2 freq_formants_noise 1.7191356\n",
      "2 bandwidth_formants_noise_hz_metric 2.4856262\n",
      "2 bandwidth_formants_noise_hz 7.4568787\n",
      "2 Ldiff 0.031988136\n",
      "2 Lexp -0.1526647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [10:37<5:42:57, 212.14s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/47 [00:02<01:41,  2.20s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:04<01:31,  2.03s/it]\u001b[A\n",
      "  6%|▋         | 3/47 [00:06<01:27,  1.98s/it]\u001b[A\n",
      "  9%|▊         | 4/47 [00:07<01:24,  1.97s/it]\u001b[A\n",
      " 11%|█         | 5/47 [00:10<01:23,  2.00s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:11<01:19,  1.94s/it]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:13<01:17,  1.93s/it]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:15<01:14,  1.92s/it]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:17<01:12,  1.92s/it]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:19<01:10,  1.90s/it]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:21<01:07,  1.87s/it]\u001b[A\n",
      " 26%|██▌       | 12/47 [00:23<01:06,  1.89s/it]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:25<01:04,  1.91s/it]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:27<01:03,  1.93s/it]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:28<01:00,  1.88s/it]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:30<00:57,  1.86s/it]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:32<00:55,  1.85s/it]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:34<00:55,  1.90s/it]\u001b[A\n",
      " 40%|████      | 19/47 [00:36<00:52,  1.89s/it]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:38<00:50,  1.89s/it]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:40<00:50,  1.94s/it]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:42<00:48,  1.95s/it]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:44<00:45,  1.92s/it]\u001b[A\n",
      " 51%|█████     | 24/47 [00:45<00:42,  1.86s/it]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:47<00:40,  1.83s/it]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:49<00:40,  1.91s/it]\u001b[A\n",
      " 57%|█████▋    | 27/47 [00:51<00:37,  1.86s/it]\u001b[A\n",
      " 60%|█████▉    | 28/47 [00:53<00:35,  1.86s/it]\u001b[A\n",
      " 62%|██████▏   | 29/47 [00:55<00:33,  1.87s/it]\u001b[A\n",
      " 64%|██████▍   | 30/47 [00:57<00:31,  1.86s/it]\u001b[A\n",
      " 66%|██████▌   | 31/47 [00:58<00:29,  1.84s/it]\u001b[A\n",
      " 68%|██████▊   | 32/47 [01:00<00:27,  1.86s/it]\u001b[A\n",
      " 70%|███████   | 33/47 [01:02<00:25,  1.82s/it]\u001b[A\n",
      " 72%|███████▏  | 34/47 [01:04<00:24,  1.86s/it]\u001b[A\n",
      " 74%|███████▍  | 35/47 [01:06<00:21,  1.83s/it]\u001b[A\n",
      " 77%|███████▋  | 36/47 [01:08<00:20,  1.83s/it]\u001b[A\n",
      " 79%|███████▊  | 37/47 [01:09<00:18,  1.83s/it]\u001b[A\n",
      " 81%|████████  | 38/47 [01:11<00:16,  1.84s/it]\u001b[A\n",
      " 83%|████████▎ | 39/47 [01:13<00:14,  1.86s/it]\u001b[A\n",
      " 85%|████████▌ | 40/47 [01:15<00:12,  1.85s/it]\u001b[A\n",
      " 87%|████████▋ | 41/47 [01:17<00:11,  1.85s/it]\u001b[A\n",
      " 89%|████████▉ | 42/47 [01:19<00:09,  1.82s/it]\u001b[A\n",
      " 91%|█████████▏| 43/47 [01:20<00:07,  1.84s/it]\u001b[A\n",
      " 94%|█████████▎| 44/47 [01:22<00:05,  1.83s/it]\u001b[A\n",
      " 96%|█████████▌| 45/47 [01:24<00:03,  1.86s/it]\u001b[A\n",
      " 98%|█████████▊| 46/47 [01:26<00:01,  1.87s/it]\u001b[A\n",
      "100%|██████████| 47/47 [01:28<00:00,  1.88s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "tensor([1.])\n",
      "save test result!\n",
      "2023-06-11 00:29:54,623 logger INFO: Saving checkpoint to output/resnet/model_epoch3_NY869.pth\n",
      "registering means,n_iter,self.n_iters 3 [0, 1, 2]\n",
      "3 Lae_a1 0.0\n",
      "3 Lae_a_l21 0.0\n",
      "3 Lae_db1 0.2529148\n",
      "3 Lae_db_l21 0.25295347\n",
      "3 Lae_a2 0.0\n",
      "3 Lae_a_l22 0.0\n",
      "3 Lae_db2 0.24246448\n",
      "3 Lae_db_l22 0.2424764\n",
      "3 Lrec 19.81517\n",
      "3 loudness_metric 0.014596612\n",
      "3 loudness 3.9722514\n",
      "3 f0_metric 0.05654022\n",
      "3 f0_hz 0.016962066\n",
      "3 amplitudes_metric 0.011870064\n",
      "3 amplitudes 6.6364255\n",
      "3 amplitude_formants_hamon_metric 0.0006661497\n",
      "3 amplitude_formants_hamon 0.26645988\n",
      "3 freq_formants_hamon_hz_metric_2 0.06628768\n",
      "3 freq_formants_hamon_hz_metric_6 0.09544511\n",
      "3 freq_formants_hamon 0.16504097\n",
      "3 amplitude_formants_noise_metric 0.0019245798\n",
      "3 amplitude_formants_noise 0.76983196\n",
      "3 freq_formants_noise_metric 0.3396586\n",
      "3 freq_formants_noise 1.6041679\n",
      "3 bandwidth_formants_noise_hz_metric 2.4651892\n",
      "3 bandwidth_formants_noise_hz 7.395568\n",
      "3 Ldiff 0.033016272\n",
      "3 Lexp -0.15606645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [14:08<5:38:29, 211.56s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/47 [00:02<01:37,  2.11s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:04<01:32,  2.06s/it]\u001b[A\n",
      "  6%|▋         | 3/47 [00:05<01:26,  1.96s/it]\u001b[A\n",
      "  9%|▊         | 4/47 [00:07<01:22,  1.92s/it]\u001b[A\n",
      " 11%|█         | 5/47 [00:09<01:19,  1.89s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:11<01:16,  1.88s/it]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:13<01:14,  1.86s/it]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:15<01:12,  1.87s/it]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:17<01:10,  1.85s/it]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:18<01:08,  1.84s/it]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:20<01:06,  1.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registering means,n_iter,self.n_iters 200 []\n",
      "200 Lae_a1 0.0\n",
      "200 Lae_a_l21 0.0\n",
      "200 Lae_db1 0.27113318\n",
      "200 Lae_db_l21 0.2711629\n",
      "200 Lae_a2 0.0\n",
      "200 Lae_a_l22 0.0\n",
      "200 Lae_db2 0.2693394\n",
      "200 Lae_db_l22 0.26935026\n",
      "200 Lrec 21.618902\n",
      "200 loudness_metric 0.020677581\n",
      "200 loudness 4.934557\n",
      "200 f0_metric 1.1471866\n",
      "200 f0_hz 0.344156\n",
      "200 amplitudes_metric 0.015297581\n",
      "200 amplitudes 2.818128\n",
      "200 amplitude_formants_hamon_metric 0.0009018101\n",
      "200 amplitude_formants_hamon 0.36072406\n",
      "200 freq_formants_hamon_hz_metric_2 0.112008184\n",
      "200 freq_formants_hamon_hz_metric_6 0.1562096\n",
      "200 freq_formants_hamon 0.34439036\n",
      "200 amplitude_formants_noise_metric 0.0022607953\n",
      "200 amplitude_formants_noise 0.9043181\n",
      "200 freq_formants_noise_metric 0.49177328\n",
      "200 freq_formants_noise 2.3247125\n",
      "200 bandwidth_formants_noise_hz_metric 2.889857\n",
      "200 bandwidth_formants_noise_hz 8.669572\n",
      "200 Ldiff 0.1407026\n",
      "200 Lexp -0.28287488\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 12/47 [00:22<01:05,  1.87s/it]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:24<01:02,  1.85s/it]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:26<01:01,  1.87s/it]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:28<00:59,  1.86s/it]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:30<00:57,  1.86s/it]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:31<00:55,  1.85s/it]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:33<00:53,  1.86s/it]\u001b[A\n",
      " 40%|████      | 19/47 [00:35<00:51,  1.82s/it]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:37<00:48,  1.81s/it]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:39<00:46,  1.80s/it]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:40<00:45,  1.82s/it]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:42<00:43,  1.83s/it]\u001b[A\n",
      " 51%|█████     | 24/47 [00:44<00:41,  1.81s/it]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:46<00:40,  1.82s/it]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:48<00:38,  1.82s/it]\u001b[A\n",
      " 57%|█████▋    | 27/47 [00:50<00:36,  1.83s/it]\u001b[A\n",
      " 60%|█████▉    | 28/47 [00:51<00:34,  1.84s/it]\u001b[A\n",
      " 62%|██████▏   | 29/47 [00:53<00:33,  1.87s/it]\u001b[A\n",
      " 64%|██████▍   | 30/47 [00:55<00:31,  1.86s/it]\u001b[A\n",
      " 66%|██████▌   | 31/47 [00:57<00:29,  1.85s/it]\u001b[A\n",
      " 68%|██████▊   | 32/47 [00:59<00:27,  1.86s/it]\u001b[A\n",
      " 70%|███████   | 33/47 [01:01<00:25,  1.83s/it]\u001b[A\n",
      " 72%|███████▏  | 34/47 [01:03<00:24,  1.87s/it]\u001b[A\n",
      " 74%|███████▍  | 35/47 [01:04<00:21,  1.83s/it]\u001b[A\n",
      " 77%|███████▋  | 36/47 [01:06<00:20,  1.86s/it]\u001b[A\n",
      " 79%|███████▊  | 37/47 [01:08<00:18,  1.84s/it]\u001b[A\n",
      " 81%|████████  | 38/47 [01:10<00:16,  1.82s/it]\u001b[A\n",
      " 83%|████████▎ | 39/47 [01:12<00:14,  1.84s/it]\u001b[A\n",
      " 85%|████████▌ | 40/47 [01:14<00:12,  1.84s/it]\u001b[A\n",
      " 87%|████████▋ | 41/47 [01:15<00:11,  1.85s/it]\u001b[A\n",
      " 89%|████████▉ | 42/47 [01:17<00:09,  1.83s/it]\u001b[A\n",
      " 91%|█████████▏| 43/47 [01:19<00:07,  1.81s/it]\u001b[A\n",
      " 94%|█████████▎| 44/47 [01:21<00:05,  1.84s/it]\u001b[A\n",
      " 96%|█████████▌| 45/47 [01:23<00:03,  1.85s/it]\u001b[A\n",
      " 98%|█████████▊| 46/47 [01:25<00:01,  1.83s/it]\u001b[A\n",
      "100%|██████████| 47/47 [01:26<00:00,  1.85s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "tensor([1.])\n",
      "save test result!\n",
      "2023-06-11 00:33:23,584 logger INFO: Saving checkpoint to output/resnet/model_epoch4_NY869.pth\n",
      "registering means,n_iter,self.n_iters 4 [0, 1, 2, 3]\n",
      "4 Lae_a1 0.0\n",
      "4 Lae_a_l21 0.0\n",
      "4 Lae_db1 0.25042203\n",
      "4 Lae_db_l21 0.25045952\n",
      "4 Lae_a2 0.0\n",
      "4 Lae_a_l22 0.0\n",
      "4 Lae_db2 0.23778373\n",
      "4 Lae_db_l22 0.23779581\n",
      "4 Lrec 19.528229\n",
      "4 loudness_metric 0.013983068\n",
      "4 loudness 3.9601338\n",
      "4 f0_metric 0.06554264\n",
      "4 f0_hz 0.019662792\n",
      "4 amplitudes_metric 0.012523084\n",
      "4 amplitudes 6.6537027\n",
      "4 amplitude_formants_hamon_metric 0.00063714007\n",
      "4 amplitude_formants_hamon 0.25485602\n",
      "4 freq_formants_hamon_hz_metric_2 0.090070926\n",
      "4 freq_formants_hamon_hz_metric_6 0.100258276\n",
      "4 freq_formants_hamon 0.18413046\n",
      "4 amplitude_formants_noise_metric 0.0018124974\n",
      "4 amplitude_formants_noise 0.72499895\n",
      "4 freq_formants_noise_metric 0.3656872\n",
      "4 freq_formants_noise 1.7125032\n",
      "4 bandwidth_formants_noise_hz_metric 2.3439436\n",
      "4 bandwidth_formants_noise_hz 7.031831\n",
      "4 Ldiff 0.029060617\n",
      "4 Lexp -0.15977377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [17:37<5:33:43, 210.78s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/47 [00:02<01:58,  2.57s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:04<01:48,  2.42s/it]\u001b[A\n",
      "  6%|▋         | 3/47 [00:07<01:45,  2.40s/it]\u001b[A\n",
      "  9%|▊         | 4/47 [00:09<01:39,  2.32s/it]\u001b[A\n",
      " 11%|█         | 5/47 [00:11<01:39,  2.36s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:14<01:35,  2.33s/it]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:16<01:32,  2.32s/it]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:18<01:30,  2.31s/it]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:21<01:27,  2.29s/it]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:23<01:23,  2.25s/it]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:25<01:20,  2.24s/it]\u001b[A\n",
      " 26%|██▌       | 12/47 [00:27<01:18,  2.24s/it]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:29<01:15,  2.22s/it]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:31<01:11,  2.18s/it]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:34<01:11,  2.23s/it]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:36<01:07,  2.19s/it]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:38<01:05,  2.19s/it]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:40<01:03,  2.19s/it]\u001b[A\n",
      " 40%|████      | 19/47 [00:42<01:01,  2.18s/it]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:45<00:58,  2.16s/it]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:47<00:55,  2.14s/it]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:49<00:53,  2.14s/it]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:51<00:50,  2.12s/it]\u001b[A\n",
      " 51%|█████     | 24/47 [00:53<00:48,  2.13s/it]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:55<00:47,  2.15s/it]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:57<00:45,  2.17s/it]\u001b[A\n",
      " 57%|█████▋    | 27/47 [01:00<00:43,  2.19s/it]\u001b[A\n",
      " 60%|█████▉    | 28/47 [01:02<00:41,  2.18s/it]\u001b[A\n",
      " 62%|██████▏   | 29/47 [01:04<00:39,  2.20s/it]\u001b[A\n",
      " 64%|██████▍   | 30/47 [01:06<00:36,  2.18s/it]\u001b[A\n",
      " 66%|██████▌   | 31/47 [01:08<00:34,  2.16s/it]\u001b[A\n",
      " 68%|██████▊   | 32/47 [01:10<00:32,  2.16s/it]\u001b[A\n",
      " 70%|███████   | 33/47 [01:12<00:29,  2.12s/it]\u001b[A\n",
      " 72%|███████▏  | 34/47 [01:15<00:27,  2.12s/it]\u001b[A\n",
      " 74%|███████▍  | 35/47 [01:17<00:25,  2.13s/it]\u001b[A\n",
      " 77%|███████▋  | 36/47 [01:19<00:23,  2.12s/it]\u001b[A\n",
      " 79%|███████▊  | 37/47 [01:21<00:21,  2.14s/it]\u001b[A\n",
      " 81%|████████  | 38/47 [01:23<00:19,  2.12s/it]\u001b[A\n",
      " 83%|████████▎ | 39/47 [01:25<00:16,  2.06s/it]\u001b[A\n",
      " 85%|████████▌ | 40/47 [01:27<00:14,  2.06s/it]\u001b[A\n",
      " 87%|████████▋ | 41/47 [01:29<00:12,  2.10s/it]\u001b[A\n",
      " 89%|████████▉ | 42/47 [01:31<00:10,  2.10s/it]\u001b[A\n",
      " 91%|█████████▏| 43/47 [01:33<00:08,  2.07s/it]\u001b[A\n",
      " 94%|█████████▎| 44/47 [01:35<00:06,  2.06s/it]\u001b[A\n",
      " 96%|█████████▌| 45/47 [01:38<00:04,  2.08s/it]\u001b[A\n",
      " 98%|█████████▊| 46/47 [01:40<00:02,  2.06s/it]\u001b[A\n",
      "100%|██████████| 47/47 [01:42<00:00,  2.18s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "tensor([1.])\n",
      "save test result!\n",
      "2023-06-11 00:37:08,363 logger INFO: Saving checkpoint to output/resnet/model_epoch5_NY869.pth\n",
      "registering means,n_iter,self.n_iters 5 [0, 1, 2, 3, 4]\n",
      "5 Lae_a1 0.0\n",
      "5 Lae_a_l21 0.0\n",
      "5 Lae_db1 0.24447273\n",
      "5 Lae_db_l21 0.24451733\n",
      "5 Lae_a2 0.0\n",
      "5 Lae_a_l22 0.0\n",
      "5 Lae_db2 0.23439074\n",
      "5 Lae_db_l22 0.23440348\n",
      "5 Lrec 19.154537\n",
      "5 loudness_metric 0.014511393\n",
      "5 loudness 3.9464347\n",
      "5 f0_metric 0.07050653\n",
      "5 f0_hz 0.02115196\n",
      "5 amplitudes_metric 0.012662956\n",
      "5 amplitudes 6.6178403\n",
      "5 amplitude_formants_hamon_metric 0.0006158994\n",
      "5 amplitude_formants_hamon 0.24635975\n",
      "5 freq_formants_hamon_hz_metric_2 0.09932348\n",
      "5 freq_formants_hamon_hz_metric_6 0.09987568\n",
      "5 freq_formants_hamon 0.19431394\n",
      "5 amplitude_formants_noise_metric 0.0019648909\n",
      "5 amplitude_formants_noise 0.7859563\n",
      "5 freq_formants_noise_metric 0.3594472\n",
      "5 freq_formants_noise 1.6902386\n",
      "5 bandwidth_formants_noise_hz_metric 2.2135465\n",
      "5 bandwidth_formants_noise_hz 6.6406393\n",
      "5 Ldiff 0.028682545\n",
      "5 Lexp -0.16017021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [21:21<5:37:14, 215.26s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/47 [00:02<01:44,  2.26s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:04<01:37,  2.16s/it]\u001b[A\n",
      "  6%|▋         | 3/47 [00:06<01:33,  2.13s/it]\u001b[A\n",
      "  9%|▊         | 4/47 [00:08<01:33,  2.16s/it]\u001b[A\n",
      " 11%|█         | 5/47 [00:10<01:28,  2.11s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:12<01:25,  2.08s/it]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:14<01:24,  2.11s/it]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:17<01:23,  2.13s/it]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:19<01:20,  2.12s/it]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:21<01:18,  2.12s/it]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:23<01:16,  2.11s/it]\u001b[A\n",
      " 26%|██▌       | 12/47 [00:25<01:13,  2.11s/it]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:27<01:13,  2.16s/it]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:29<01:11,  2.17s/it]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:32<01:08,  2.16s/it]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:34<01:05,  2.12s/it]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:36<01:03,  2.10s/it]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:38<01:01,  2.11s/it]\u001b[A\n",
      " 40%|████      | 19/47 [00:40<00:58,  2.07s/it]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:42<00:55,  2.07s/it]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:44<00:53,  2.05s/it]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:46<00:50,  2.03s/it]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:48<00:48,  2.02s/it]\u001b[A\n",
      " 51%|█████     | 24/47 [00:50<00:45,  2.00s/it]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:52<00:43,  2.00s/it]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:54<00:41,  1.98s/it]\u001b[A\n",
      " 57%|█████▋    | 27/47 [00:56<00:39,  1.96s/it]\u001b[A\n",
      " 60%|█████▉    | 28/47 [00:58<00:37,  1.98s/it]\u001b[A\n",
      " 62%|██████▏   | 29/47 [01:00<00:36,  2.00s/it]\u001b[A\n",
      " 64%|██████▍   | 30/47 [01:02<00:34,  2.03s/it]\u001b[A\n",
      " 66%|██████▌   | 31/47 [01:04<00:33,  2.07s/it]\u001b[A\n",
      " 68%|██████▊   | 32/47 [01:06<00:30,  2.03s/it]\u001b[A\n",
      " 70%|███████   | 33/47 [01:08<00:28,  2.00s/it]\u001b[A\n",
      " 72%|███████▏  | 34/47 [01:10<00:25,  1.99s/it]\u001b[A\n",
      " 74%|███████▍  | 35/47 [01:12<00:24,  2.02s/it]\u001b[A\n",
      " 77%|███████▋  | 36/47 [01:14<00:21,  1.97s/it]\u001b[A\n",
      " 79%|███████▊  | 37/47 [01:16<00:20,  2.00s/it]\u001b[A\n",
      " 81%|████████  | 38/47 [01:18<00:18,  2.02s/it]\u001b[A\n",
      " 83%|████████▎ | 39/47 [01:20<00:16,  2.04s/it]\u001b[A\n",
      " 85%|████████▌ | 40/47 [01:22<00:14,  2.03s/it]\u001b[A\n",
      " 87%|████████▋ | 41/47 [01:24<00:12,  2.01s/it]\u001b[A\n",
      " 89%|████████▉ | 42/47 [01:26<00:09,  1.99s/it]\u001b[A\n",
      " 91%|█████████▏| 43/47 [01:28<00:07,  1.97s/it]\u001b[A\n",
      " 94%|█████████▎| 44/47 [01:30<00:06,  2.03s/it]\u001b[A\n",
      " 96%|█████████▌| 45/47 [01:32<00:04,  2.01s/it]\u001b[A\n",
      " 98%|█████████▊| 46/47 [01:34<00:01,  1.97s/it]\u001b[A\n",
      "100%|██████████| 47/47 [01:36<00:00,  2.05s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "tensor([1.])\n",
      "save test result!\n",
      "2023-06-11 00:40:46,226 logger INFO: Saving checkpoint to output/resnet/model_epoch6_NY869.pth\n",
      "registering means,n_iter,self.n_iters 6 [0, 1, 2, 3, 4, 5]\n",
      "6 Lae_a1 0.0\n",
      "6 Lae_a_l21 0.0\n",
      "6 Lae_db1 0.24395002\n",
      "6 Lae_db_l21 0.24399738\n",
      "6 Lae_a2 0.0\n",
      "6 Lae_a_l22 0.0\n",
      "6 Lae_db2 0.23053822\n",
      "6 Lae_db_l22 0.23055123\n",
      "6 Lrec 18.97953\n",
      "6 loudness_metric 0.016198717\n",
      "6 loudness 4.2241344\n",
      "6 f0_metric 0.07860848\n",
      "6 f0_hz 0.023582546\n",
      "6 amplitudes_metric 0.011738509\n",
      "6 amplitudes 6.5832634\n",
      "6 amplitude_formants_hamon_metric 0.00063209364\n",
      "6 amplitude_formants_hamon 0.25283745\n",
      "6 freq_formants_hamon_hz_metric_2 0.101337716\n",
      "6 freq_formants_hamon_hz_metric_6 0.09719759\n",
      "6 freq_formants_hamon 0.20050831\n",
      "6 amplitude_formants_noise_metric 0.0019563402\n",
      "6 amplitude_formants_noise 0.7825361\n",
      "6 freq_formants_noise_metric 0.37296078\n",
      "6 freq_formants_noise 1.74068\n",
      "6 bandwidth_formants_noise_hz_metric 2.2654195\n",
      "6 bandwidth_formants_noise_hz 6.7962584\n",
      "6 Ldiff 0.029629562\n",
      "6 Lexp -0.15718925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [24:59<5:35:07, 216.21s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/47 [00:02<01:48,  2.36s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:04<01:39,  2.21s/it]\u001b[A\n",
      "  6%|▋         | 3/47 [00:06<01:36,  2.19s/it]\u001b[A\n",
      "  9%|▊         | 4/47 [00:08<01:29,  2.07s/it]\u001b[A\n",
      " 11%|█         | 5/47 [00:10<01:27,  2.09s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:12<01:22,  2.02s/it]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:14<01:20,  2.02s/it]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:16<01:17,  1.99s/it]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:18<01:14,  1.96s/it]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:20<01:10,  1.91s/it]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:22<01:09,  1.92s/it]\u001b[A\n",
      " 26%|██▌       | 12/47 [00:24<01:08,  1.95s/it]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:26<01:07,  1.98s/it]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:28<01:04,  1.96s/it]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:29<01:01,  1.91s/it]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:31<00:58,  1.89s/it]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:33<00:58,  1.93s/it]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:35<00:55,  1.92s/it]\u001b[A\n",
      " 40%|████      | 19/47 [00:37<00:53,  1.92s/it]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:39<00:52,  1.95s/it]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:41<00:51,  2.00s/it]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:43<00:49,  1.98s/it]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:45<00:47,  1.99s/it]\u001b[A\n",
      " 51%|█████     | 24/47 [00:47<00:45,  1.98s/it]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:49<00:43,  1.97s/it]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:51<00:40,  1.94s/it]\u001b[A\n",
      " 57%|█████▋    | 27/47 [00:53<00:38,  1.92s/it]\u001b[A\n",
      " 60%|█████▉    | 28/47 [00:55<00:36,  1.93s/it]\u001b[A\n",
      " 62%|██████▏   | 29/47 [00:57<00:34,  1.93s/it]\u001b[A\n",
      " 64%|██████▍   | 30/47 [00:59<00:33,  1.98s/it]\u001b[A\n",
      " 66%|██████▌   | 31/47 [01:01<00:32,  2.00s/it]\u001b[A\n",
      " 68%|██████▊   | 32/47 [01:03<00:29,  1.99s/it]\u001b[A\n",
      " 70%|███████   | 33/47 [01:05<00:27,  1.94s/it]\u001b[A\n",
      " 72%|███████▏  | 34/47 [01:06<00:24,  1.91s/it]\u001b[A\n",
      " 74%|███████▍  | 35/47 [01:09<00:23,  1.94s/it]\u001b[A\n",
      " 77%|███████▋  | 36/47 [01:10<00:21,  1.93s/it]\u001b[A\n",
      " 79%|███████▊  | 37/47 [01:12<00:19,  1.96s/it]\u001b[A\n",
      " 81%|████████  | 38/47 [01:14<00:17,  1.91s/it]\u001b[A\n",
      " 83%|████████▎ | 39/47 [01:16<00:15,  1.92s/it]\u001b[A\n",
      " 85%|████████▌ | 40/47 [01:18<00:13,  1.93s/it]\u001b[A\n",
      " 87%|████████▋ | 41/47 [01:20<00:11,  1.94s/it]\u001b[A\n",
      " 89%|████████▉ | 42/47 [01:22<00:09,  1.90s/it]\u001b[A\n",
      " 91%|█████████▏| 43/47 [01:24<00:07,  1.91s/it]\u001b[A\n",
      " 94%|█████████▎| 44/47 [01:26<00:05,  1.93s/it]\u001b[A\n",
      " 96%|█████████▌| 45/47 [01:28<00:03,  1.89s/it]\u001b[A\n",
      " 98%|█████████▊| 46/47 [01:30<00:01,  1.90s/it]\u001b[A\n",
      "100%|██████████| 47/47 [01:32<00:00,  1.96s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "tensor([1.])\n",
      "save test result!\n",
      "2023-06-11 00:44:20,312 logger INFO: Saving checkpoint to output/resnet/model_epoch7_NY869.pth\n",
      "registering means,n_iter,self.n_iters 7 [0, 1, 2, 3, 4, 5, 6]\n",
      "7 Lae_a1 0.0\n",
      "7 Lae_a_l21 0.0\n",
      "7 Lae_db1 0.24728993\n",
      "7 Lae_db_l21 0.24733184\n",
      "7 Lae_a2 0.0\n",
      "7 Lae_a_l22 0.0\n",
      "7 Lae_db2 0.23472999\n",
      "7 Lae_db_l22 0.23474239\n",
      "7 Lrec 19.280796\n",
      "7 loudness_metric 0.013411522\n",
      "7 loudness 3.9291961\n",
      "7 f0_metric 0.08220282\n",
      "7 f0_hz 0.024660848\n",
      "7 amplitudes_metric 0.009881485\n",
      "7 amplitudes 6.021891\n",
      "7 amplitude_formants_hamon_metric 0.0006018083\n",
      "7 amplitude_formants_hamon 0.24072333\n",
      "7 freq_formants_hamon_hz_metric_2 0.11517214\n",
      "7 freq_formants_hamon_hz_metric_6 0.101912625\n",
      "7 freq_formants_hamon 0.21743372\n",
      "7 amplitude_formants_noise_metric 0.0019196235\n",
      "7 amplitude_formants_noise 0.7678494\n",
      "7 freq_formants_noise_metric 0.36800614\n",
      "7 freq_formants_noise 1.7432581\n",
      "7 bandwidth_formants_noise_hz_metric 2.4021375\n",
      "7 bandwidth_formants_noise_hz 7.2064123\n",
      "7 Ldiff 0.025229445\n",
      "7 Lexp -0.13631578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [28:34<5:30:53, 215.80s/it]\n",
      "  0%|          | 0/47 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n",
      "length, self.TestNum_cum [50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/47 [00:02<01:43,  2.25s/it]\u001b[A\n",
      "  4%|▍         | 2/47 [00:04<01:32,  2.05s/it]\u001b[A\n",
      "  6%|▋         | 3/47 [00:06<01:25,  1.95s/it]\u001b[A\n",
      "  9%|▊         | 4/47 [00:08<01:25,  2.00s/it]\u001b[A\n",
      " 11%|█         | 5/47 [00:10<01:23,  1.99s/it]\u001b[A\n",
      " 13%|█▎        | 6/47 [00:11<01:20,  1.95s/it]\u001b[A\n",
      " 15%|█▍        | 7/47 [00:13<01:18,  1.96s/it]\u001b[A\n",
      " 17%|█▋        | 8/47 [00:15<01:16,  1.96s/it]\u001b[A\n",
      " 19%|█▉        | 9/47 [00:17<01:14,  1.95s/it]\u001b[A\n",
      " 21%|██▏       | 10/47 [00:19<01:10,  1.91s/it]\u001b[A\n",
      " 23%|██▎       | 11/47 [00:21<01:07,  1.88s/it]\u001b[A\n",
      " 26%|██▌       | 12/47 [00:23<01:05,  1.88s/it]\u001b[A\n",
      " 28%|██▊       | 13/47 [00:25<01:03,  1.88s/it]\u001b[A\n",
      " 30%|██▉       | 14/47 [00:27<01:02,  1.89s/it]\u001b[A\n",
      " 32%|███▏      | 15/47 [00:29<01:01,  1.92s/it]\u001b[A\n",
      " 34%|███▍      | 16/47 [00:30<00:58,  1.87s/it]\u001b[A\n",
      " 36%|███▌      | 17/47 [00:32<00:55,  1.86s/it]\u001b[A\n",
      " 38%|███▊      | 18/47 [00:34<00:56,  1.94s/it]\u001b[A\n",
      " 40%|████      | 19/47 [00:36<00:54,  1.94s/it]\u001b[A\n",
      " 43%|████▎     | 20/47 [00:38<00:52,  1.94s/it]\u001b[A\n",
      " 45%|████▍     | 21/47 [00:40<00:50,  1.95s/it]\u001b[A\n",
      " 47%|████▋     | 22/47 [00:42<00:48,  1.93s/it]\u001b[A\n",
      " 49%|████▉     | 23/47 [00:44<00:45,  1.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registering means,n_iter,self.n_iters 400 [200]\n",
      "400 Lae_a1 0.0\n",
      "400 Lae_a_l21 0.0\n",
      "400 Lae_db1 0.2463071\n",
      "400 Lae_db_l21 0.24634786\n",
      "400 Lae_a2 0.0\n",
      "400 Lae_a_l22 0.0\n",
      "400 Lae_db2 0.24559443\n",
      "400 Lae_db_l22 0.24560662\n",
      "400 Lrec 19.676062\n",
      "400 loudness_metric 0.01755958\n",
      "400 loudness 3.782256\n",
      "400 f0_metric 0.25544336\n",
      "400 f0_hz 0.07663301\n",
      "400 amplitudes_metric 0.015976695\n",
      "400 amplitudes 2.8186743\n",
      "400 amplitude_formants_hamon_metric 0.00073728967\n",
      "400 amplitude_formants_hamon 0.29491585\n",
      "400 freq_formants_hamon_hz_metric_2 0.12903315\n",
      "400 freq_formants_hamon_hz_metric_6 0.12295094\n",
      "400 freq_formants_hamon 0.2576533\n",
      "400 amplitude_formants_noise_metric 0.0023036078\n",
      "400 amplitude_formants_noise 0.9214431\n",
      "400 freq_formants_noise_metric 0.4097411\n",
      "400 freq_formants_noise 1.932734\n",
      "400 bandwidth_formants_noise_hz_metric 2.2368677\n",
      "400 bandwidth_formants_noise_hz 6.710603\n",
      "400 Ldiff 0.07741421\n",
      "400 Lexp -0.28138924\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 51%|█████     | 24/47 [00:46<00:45,  1.98s/it]\u001b[A\n",
      " 53%|█████▎    | 25/47 [00:48<00:43,  1.96s/it]\u001b[A\n",
      " 55%|█████▌    | 26/47 [00:50<00:41,  1.96s/it]\u001b[A\n",
      " 57%|█████▋    | 27/47 [00:52<00:38,  1.93s/it]\u001b[A\n",
      " 60%|█████▉    | 28/47 [00:54<00:36,  1.93s/it]\u001b[A\n",
      " 62%|██████▏   | 29/47 [00:56<00:34,  1.90s/it]\u001b[A\n",
      " 64%|██████▍   | 30/47 [00:58<00:32,  1.92s/it]\u001b[A\n",
      " 66%|██████▌   | 31/47 [01:00<00:31,  1.99s/it]\u001b[A\n",
      " 68%|██████▊   | 32/47 [01:01<00:28,  1.93s/it]\u001b[A\n",
      " 70%|███████   | 33/47 [01:04<00:28,  2.01s/it]\u001b[A\n",
      " 72%|███████▏  | 34/47 [01:05<00:25,  1.96s/it]\u001b[A\n",
      " 74%|███████▍  | 35/47 [01:07<00:22,  1.89s/it]\u001b[A\n",
      " 77%|███████▋  | 36/47 [01:09<00:20,  1.86s/it]\u001b[A\n",
      " 79%|███████▊  | 37/47 [01:11<00:19,  1.92s/it]\u001b[A\n",
      " 81%|████████  | 38/47 [01:13<00:17,  1.96s/it]\u001b[A\n",
      " 83%|████████▎ | 39/47 [01:15<00:15,  1.94s/it]\u001b[A\n",
      " 85%|████████▌ | 40/47 [01:17<00:13,  1.91s/it]\u001b[A\n",
      " 87%|████████▋ | 41/47 [01:19<00:11,  1.93s/it]\u001b[A\n",
      " 89%|████████▉ | 42/47 [01:21<00:09,  1.92s/it]\u001b[A\n",
      " 91%|█████████▏| 43/47 [01:23<00:07,  1.90s/it]\u001b[A\n",
      " 94%|█████████▎| 44/47 [01:25<00:05,  1.93s/it]\u001b[A\n",
      " 96%|█████████▌| 45/47 [01:26<00:03,  1.92s/it]\u001b[A\n",
      " 98%|█████████▊| 46/47 [01:28<00:01,  1.90s/it]\u001b[A\n",
      "100%|██████████| 47/47 [01:30<00:00,  1.93s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length, self.TestNum_cum [50]\n",
      "tensor([1.])\n",
      "save test result!\n",
      "2023-06-11 00:47:53,555 logger INFO: Saving checkpoint to output/resnet/model_epoch8_NY869.pth\n",
      "registering means,n_iter,self.n_iters 8 [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "8 Lae_a1 0.0\n",
      "8 Lae_a_l21 0.0\n",
      "8 Lae_db1 0.22700496\n",
      "8 Lae_db_l21 0.22705537\n",
      "8 Lae_a2 0.0\n",
      "8 Lae_a_l22 0.0\n",
      "8 Lae_db2 0.22505563\n",
      "8 Lae_db_l22 0.22506937\n",
      "8 Lrec 18.082424\n",
      "8 loudness_metric 0.013084595\n",
      "8 loudness 3.1863556\n",
      "8 f0_metric 0.09715257\n",
      "8 f0_hz 0.029145772\n",
      "8 amplitudes_metric 0.011779965\n",
      "8 amplitudes 6.414452\n",
      "8 amplitude_formants_hamon_metric 0.00062535494\n",
      "8 amplitude_formants_hamon 0.25014198\n",
      "8 freq_formants_hamon_hz_metric_2 0.14478149\n",
      "8 freq_formants_hamon_hz_metric_6 0.11209976\n",
      "8 freq_formants_hamon 0.25550583\n",
      "8 amplitude_formants_noise_metric 0.0021536024\n",
      "8 amplitude_formants_noise 0.86144096\n",
      "8 freq_formants_noise_metric 0.36376724\n",
      "8 freq_formants_noise 1.7274042\n",
      "8 bandwidth_formants_noise_hz_metric 2.2072618\n",
      "8 bandwidth_formants_noise_hz 6.621785\n",
      "8 Ldiff 0.025003703\n",
      "8 Lexp -0.15680097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [31:59<6:07:56, 239.97s/it]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-b13e55f54dc2>\", line 7, in <module>\n",
      "    args_=args_,\n",
      "  File \"/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding/utils/launcher.py\", line 174, in run\n",
      "    _run(0, world_size, fn, defaults, write_log, no_cuda, args_)\n",
      "  File \"/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding/utils/launcher.py\", line 158, in _run\n",
      "    fn(**matching_args_)\n",
      "  File \"<ipython-input-10-a02f4c11cfd6>\", line 309, in train\n",
      "    suffix=subject,\n",
      "  File \"/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding/utils/save.py\", line 981, in save_sample\n",
      "    129,\n",
      "  File \"/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding/utils/save.py\", line 117, in mygriffinlim\n",
      "    wave_gt[i] = griffinlim(msgram[i] ** 0.5, hop_length=hop_length)\n",
      "  File \"/ext3/miniconda3/lib/python3.7/site-packages/librosa/core/spectrum.py\", line 2415, in griffinlim\n",
      "    pad_mode=pad_mode,\n",
      "  File \"/ext3/miniconda3/lib/python3.7/site-packages/librosa/core/spectrum.py\", line 258, in stft\n",
      "    fft_window * y_frames[:, bl_s:bl_t], axis=0\n",
      "  File \"<__array_function__ internals>\", line 6, in rfft\n",
      "  File \"/ext3/miniconda3/lib/python3.7/site-packages/numpy/fft/_pocketfft.py\", line 409, in rfft\n",
      "    output = _raw_fft(a, n, axis, True, True, inv_norm)\n",
      "  File \"/ext3/miniconda3/lib/python3.7/site-packages/numpy/fft/_pocketfft.py\", line 73, in _raw_fft\n",
      "    r = pfi.execute(a, is_real, is_forward, fct)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/ext3/miniconda3/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/ext3/miniconda3/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/ext3/miniconda3/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/ext3/miniconda3/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/ext3/miniconda3/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/ext3/miniconda3/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/ext3/miniconda3/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-b13e55f54dc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mworld_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpu_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0margs_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding/utils/launcher.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fn, defaults, description, default_config, world_size, write_log, no_cuda, args_)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_cuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding/utils/launcher.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(rank, world_size, fn, defaults, write_log, no_cuda, args_)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mmatching_args_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs__to_pass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmatching_args_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-a02f4c11cfd6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cfg, logger, local_rank, world_size, distributed)\u001b[0m\n\u001b[1;32m    308\u001b[0m                     \u001b[0mseq_out_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m                     \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m                 )\n",
      "\u001b[0;32m/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding/utils/save.py\u001b[0m in \u001b[0;36msave_sample\u001b[0;34m(cfg, sample, ecog, encoder, decoder, ecog_encoder, encoder2, epoch, label, x_denoise, decoder_mel, mode, path, tracker, linear, n_fft, duomask, x_amp, gender, sample_wave, sample_wave_denoise, on_stage_wider, auto_regressive, seq_out_start, suffix)\u001b[0m\n\u001b[1;32m    980\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m                         \u001b[0;36m129\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m                     )\n",
      "\u001b[0;32m/scratch/xc1490/projects/ecog/ALAE_1023/neural_speech_decoding/utils/save.py\u001b[0m in \u001b[0;36mmygriffinlim\u001b[0;34m(msgram, hop_length)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsgram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mwave_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgriffinlim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsgram\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhop_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwave_gt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mgriffinlim\u001b[0;34m(S, n_iter, hop_length, win_length, window, center, dtype, length, pad_mode, momentum, init, random_state)\u001b[0m\n\u001b[1;32m   2414\u001b[0m             \u001b[0mcenter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcenter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2415\u001b[0;31m             \u001b[0mpad_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2416\u001b[0m         )\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/librosa/core/spectrum.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(y, n_fft, hop_length, win_length, window, center, dtype, pad_mode)\u001b[0m\n\u001b[1;32m    257\u001b[0m         stft_matrix[:, bl_s:bl_t] = fft.rfft(\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mfft_window\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_s\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbl_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         )\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mrfft\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36mrfft\u001b[0;34m(a, n, axis, norm)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0minv_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_forward_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_fft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/numpy/fft/_pocketfft.py\u001b[0m in \u001b[0;36m_raw_fft\u001b[0;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswapaxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ext3/miniconda3/lib/python3.7/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "run(\n",
    "    train,\n",
    "    cfg,\n",
    "    description=\"StyleGAN\",\n",
    "    default_config=config_file,\n",
    "    world_size=gpu_count,\n",
    "    args_=args_,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm data/NY869.h5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c81b04715944cdaa8152e7e2670089a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ecog_alldataset\n",
      "label_alldataset\n",
      "formant_re_alldataset\n",
      "pitch_re_alldataset\n",
      "intensity_re_alldataset\n",
      "start_ind_re_valid_alldataset\n",
      "end_ind_re_valid_alldataset\n",
      "wave_re_spec_alldataset\n",
      "wave_re_alldataset\n",
      "wave_re_spec_amp_alldataset\n",
      "noisesample_re_alldataset\n"
     ]
    }
   ],
   "source": [
    "#!rsync ../data/data/LD_data_extracted/meta_data/NY869.h5 data/\n",
    "#mv data/NY869.h5 data/NY869_full.h5\n",
    "from tqdm.notebook import tqdm\n",
    "meta_data = h5py.File('data/NY869_full.h5')\n",
    "keys_to_store = ['ecog_alldataset','label_alldataset',\\\n",
    "'formant_re_alldataset','pitch_re_alldataset','intensity_re_alldataset',\\\n",
    "'start_ind_re_valid_alldataset','end_ind_re_valid_alldataset','wave_re_spec_alldataset',\\\n",
    "'wave_re_alldataset','wave_re_spec_amp_alldataset','noisesample_re_alldataset']\n",
    "with h5py.File('data/NY869.h5' , 'w') as hf:\n",
    "    for key in tqdm(keys_to_store):\n",
    "        print (key)\n",
    "        hf.create_dataset(key,  data= meta_data[key][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
